<!--
kate: indent-width 4; word-wrap-column 74; default-dictionary en_AU
Copyright (C) 2020, Marek Gagolewski, https://www.gagolewski.com
This material is licensed under the Creative Commons BY-NC-ND 4.0 License.
-->

# Feature Selection {#chap:feature-selection}



{ LATEX \color{gray} }

**TODO** In this chapter, we will:

* ...

* ...


{ LATEX \normalcolor }






<!--

TODO : actually do some combinatorial optimisation

variable selection for lm/glm????

tabu search???

-->



## Introduction

### Recap





Recall that an **optimisation task** deals with finding an element $\mathbf{x}$
in a **search space** $\mathbb{D}$,
that minimises or maximises an **objective function** $f:\mathbb{D}\to\mathbb{R}$:
\[
\min_{\mathbf{x}\in \mathbb{D}} f(\mathbf{x}) \quad\text{or}\quad\max_{\mathbf{x}\in \mathbb{D}} f(\mathbf{x}),
\]


In one of the previous chapters, we were dealing with
**unconstrained continuous optimisation**,
i.e., we assumed the search space is $\mathbb{D}=\mathbb{R}^p$ for some $p$.

\ \

Example problems of this kind: minimising mean squared error
in linear regression
or minimising cross-entropy in logistic regression.





The class of general-purpose iterative algorithms we've previously studied
fit into the following scheme:


1. $\mathbf{x}^{(0)}$ -- initial guess (e.g., generated at random)

2. for $i=1,...,M$:
    a. $\mathbf{x}^{(i)} = \mathbf{x}^{(i-1)}+\text{[guessed direction, e.g.,}-\eta\nabla f(\mathbf{x})\text{]}$
    b. if $|f(\mathbf{x}^{(i)})-f(\mathbf{x}^{(i-1)})| < \varepsilon$ break

3. return $\mathbf{x}^{(i)}$ as result


where:

* $M$ = maximum number of iterations
* $\varepsilon$ = tolerance, e.g, $10^{-8}$
* $\eta>0$ = learning rate




The algorithms such as gradient descent and BFGS (see `optim()`)
give satisfactory results in the case of **smooth and well-behaving objective functions**.

However, if an objective has, e.g., many plateaus (regions where it is almost constant),
those methods might easily get stuck in local minima.

The K-means clustering's objective function is a not particularly pleasant
one -- it involves a nested search for the closest cluster, with the use of the $\min$ operator.




## Outro

### Remarks





For any $p\ge 1$, the search space type determines the problem class:

- $\mathbb{D}\subseteq\mathbb{R}^p$ -- **continuous optimisation**

    In particular:

    - $\mathbb{D}=\mathbb{R}^p$ -- continuous unconstrained
    - $\mathbb{D}=[a_1,b_1]\times\dots\times[a_n,b_n]$ -- continuous with box constraints
    - constrained with $k$ linear inequality constraints

        \[
        \left\{
        \begin{array}{lll}
        a_{1,1} x_1 + \dots + a_{1,p} x_p &\le& b_1 \\
        &\vdots&\\
        a_{k,1} x_1 + \dots + a_{k,p} x_p &\le& b_k \\
        \end{array}
        \right.
        \]




However, there are other possibilities as well:

- $\mathbb{D}\subseteq\mathbb{Z}^p$ ($\mathbb{Z}$ -- the set of integers) -- **discrete optimisation**

    In particular:
    - $\mathbb{D}=\{0,1\}^p$ -- 0--1 optimisation (hard!)


- $\mathbb{D}$ is finite (but perhaps large, its objects can be enumerated) -- **combination optimisation**

    For example:
    - $\mathbb{D}=$ all possible routes between two points on a map.

> These  optimisation tasks tend to be much harder than the continuous ones.

Genetic algorithms might come in handy in such cases.






Specialised methods, customised to solve a specific problem (like Lloyd's algorithm)
will often outperform generic ones (like SGD, genetic algorithms)
in terms of speed and reliability.


All in all, we prefer a suboptimal solution obtained by means of heuristics
to no solution at all.




Problems that you could try solving with GAs include variable selection
in multiple regression -- finding the subset of features optimising the AIC
(this is a hard problem to and forward selection was just a simple greed heuristic).




{ LATEX \color{gray} }

. . .

**TODO** .....


. . .

{ LATEX \normalcolor }


further reading ...

next chapter ...

