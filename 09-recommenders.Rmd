# Recommender Systems

<!-- (C) 2020 Marek Gagolewski, https://www.gagolewski.com -->


## Introduction

### What is a Recommender System?

---

A **recommender (recommendation) system**
is a method to predict the rating a **user** would give to an **item**.

For example:

- Playlist generators at Spotify, YouTube or Netflix,
- Content recommendations on Facebook, Instagram, Twitter or Apple News,
- Product recommendations at Amazon or Alibaba.


---

[@ricci_etal] list the following functions of recommender systems:

- increase the number of items sold
- sell more diverse items
- increase users' satisfaction
- increase users' fidelity
- better understand what users want


### The Netflix Prize

---

One of the most famous benchmark sets for recommender systems,
it helped boost the research on algorithms in this field.

See https://www.kaggle.com/netflix-inc/netflix-prize-data

Data archived at
https://web.archive.org/web/20090925184737/http://archive.ics.uci.edu/ml/datasets/Netflix+Prize
and https://archive.org/details/nf_prize_dataset.tar


In 2006 Netflix provided a data set that consists of:

- 480,189 users
- 17,770 movies
- 100,480,507 ratings in the training sample:

    - `MovieID`
    - `CustomerID`
    - `Rating` from 1 to 5
    - `Title`
    - `YearOfRelease` from 1890 to 2005
    - `Date` of rating in the range 1998-11-01 to 2005-12-31

> Note that up until 2010, Netflix was mainly a DVD rental company.

---

The *quiz set* consists of 1,408,342 ratings
and it was used by the competitors to assess the quality of their
algorithms and compute leaderboard scores.

Root mean squared error (RMSE) of predicted vs. true rankings was chosen as a
performance metric.

The *test set* of 1,408,789 ratings was used to determine the winner.

On 21 Sept. 2009, the grand prize of US\$1,000,000 was given
to the BellKor's Pragmatic Chaos team which improved over the Netflix's *Cinematch* algorithm  by 10.06%,
achieving the winning RMSE of 0.8567 on the test subset.



### Main Approaches

---

Current recommender systems are quite complex and use a fusion
of various approaches, also those based on external knowledge bases.

However, we may distinguish at least two core approaches,
see [@ricci_etal] for more:

- *Collaborative Filtering*

    It is based on the assumption that if two people interact with the same product,
they're likely to have other interests in common as well.

    > John and Mary both like bananas and apples and dislike spinach. John likes
sushi. Mary hasn't tried sushi yet. It seems they might have similar tastes,
so we recommend that Mary should give sushi a try.



- *Content-based Filtering*

    It builds a user's profile that represent information
of what kind of products does she/he like.

    > We have discovered that John likes fruits but dislikes vegetables.
    An orange is a fruit (an item similar to those he liked in the past)
    with which John is yet to interact. John should
    give it a try.

---

Jim Bennett, vice president of recommendations systems at Netflix
on the idea behind the original Cinematch algorithm (see https://www.technologyreview.com/s/406637/the-1-million-netflix-challenge/):

> First, you collect 100 million user ratings for about 18,000 movies. Take any two movies and find the people who have rated both of them. Then look to see if the people who rate one of the movies highly rate the other one highly, if they liked one and not the other, or if they didn’t like either movie. Based on their ratings, Cinematch sees whether there’s a correlation between those people. Now, do this for all possible pairs of 65,000 movies.

See also: https://web.archive.org/web/20070821194257/http://www.netflixprize.com/faq


> Is it an example of collaborative or context-based filtering?

<!--
How does Cinematch do it?

Straightforward statistical linear models with a lot of data conditioning. But a real-world system is much more than an algorithm, and Cinematch does a lot more than just optimize for RMSE. After all, we have a website to support. In production we have to worry about system scaling and performance, and we have additional sources to data we can use to guide our recommendations.

Netflix Prize FAQ https://web.archive.org/web/20070821194257/http://www.netflixprize.com/faq-->




### Formalism

---

Let $\mathcal{U}=\{ U_1,\dots,U_m \}$ denote the set of $m$ users.

Let $\mathcal{I}=\{ I_1,\dots,I_n \}$ denote the set of $n$ items.


Let $R\in\mathbb{R}^{m\times n}$ be a user-item matrix such that:
\[
r_{u,i}=\left\{
\begin{array}{ll}
r & \text{if the $u$-th user ranked the $i$-th item as $r>0$}\\
0 & \text{if the $u$-th user hasn't interacted with the $i$-th item yet}\\
\end{array}
\right.
\]

> Note that here `0` is used to denote a missing value (`NA`)


In particular, we can assume:

- $r_{u,i}\in\{0,1,\dots,5\}$ (ratings on the scale 1--5 or no interaction)
- $r_{u,i}\in\{0,1\}$ ("Like" or no interaction)


The aim of an recommender system is to predict the rating $\hat{r}_{u,i}$
that the $u$-th user would give to the $i$-th item provided that currently
$r_{u,i}=0$.





## Collaborative Filtering

### Example

---

In **user-based collaborative filtering**, we seek users with similar preference profiles
/rating patters.

> "User A has similar behavioural patterns as user B, so we should suggest
    A what B likes."

In **item-based collaborative filtering**, we seek items with similar (dis)likeability
structure.

> "Users who (dis)liked X also (dis)liked Y".


   .   | Apple   | Banana  |  Sushi    |  Spinach |  Orange   |
-------|---------|---------|-----------|----------|-----------|
Anna   |   1     |   5     |   5       |          |   1       |
Beth   |   1     |   1     |   5       |    5     |   1       |
John   |   5     |   5     |           |    1     |           |
Kate   |   1     |   1     |   5       |    5     |   1       |
Mark   |   5     |   5     |   1       |    1     |   5       |
Sera   |   ?     |   5     |           |    ?     |   5       |


> Will Sera enjoy her spinach?
> Will Sera enjoy her apple?

---

```{r}
R <- matrix(
    c(
     1, 5, 5, 0, 1,
     1, 1, 5, 5, 1,
     5, 5, 0, 1, 0,
     1, 1, 5, 5, 1,
     5, 5, 1, 1, 5,
     0, 5, 0, 0, 5
    ), byrow=TRUE, nrow=6, ncol=5,
    dimnames=list(
        c("Anna", "Beth", "John", "Kate", "Mark", "Sera"),
        c("Apple", "Banana", "Sushi", "Spinach", "Orange")
    )
)
```

---

```{R}
R
```


### Similarity Measures

---



Assuming $\mathbf{a},\mathbf{b}\in\mathbb{N}^k$
(in our setting, $k\in\{n,m\}$),
let $S$ be the following similarity measure between two vectors of identical lengths
(representing ratings):


\[
S(\mathbf{a},\mathbf{b}) = \frac{ \sum_{i=1}^k a_i b_i
}{
\sqrt{ \sum_{i=1}^k a_i^2 }
\sqrt{ \sum_{i=1}^k b_i^2 }
} \ge 0
\]

```{r}
cosim <- function(a, b) sum(a*b)/sqrt(sum(a^2)*sum(b^2))
```

We call it the **cosine similarity**.


> (\*) Another frequently considered similarity measure
is a version of the Pearson correlation coefficient that
ignores all $0$-valued observations,
see also the `use` argument to the `cor()` function.



### User-Based Collaborative Filtering

---

**User-based** approaches involve comparing each user against every other user
(pairwise comparisons of the rows in $R$). This yields a similarity degree
between the $i$-th and the $j$-th user:

\[
s^U_{i,j} = S(\mathbf{r}_{i,\cdot},\mathbf{r}_{j,\cdot}).
\]



```{R}
SU <- matrix(0, nrow=nrow(R), ncol=nrow(R),
    dimnames=dimnames(R)[c(1,1)]) # and empty m*m matrix
for (i in 1:nrow(R)) {
    for (j in 1:nrow(R)) {
        SU[i,j] <- cosim(R[i,], R[j,])
    }
}
```

---

```{R}
round(SU, 2)
```

---

In order to obtain the previously unobserved
rating $\hat{r}_{u,i}$ using the user-based approach, we typically
look for the $K$ most similar users and aggregate their corresponding
scores (for some $K\ge 1$)

> More formally, let $\{U_{v_1},\dots,U_{v_K}\}\in\mathcal{U}\setminus\{U_u\}$ be the set
    of users maximising $s^U_{u, v_1}, \dots, s^U_{u, v_K}$
    and having $r_{v_1, i},\dots,r_{v_K, i}>0$.
    Then    \[
    \hat{r}_{u,i} = \frac{1}{K} \sum_{\ell=1}^K r_{v_\ell, i}.
    \]

> The arithmetic mean can be replaced with, e.g.,
a weighted arithmetic mean where weights are proportional to $s^U_{u, v_\ell}$
or the mode.

> This is similar to the $K$-nearest neighbour heuristic.

---


```{R}
K <- 2
(sim <- order(SU["Sera",],decreasing=TRUE))
# sim gives the indexes of people in decreasing order
# of similarity to Sera:
dimnames(R)[[1]][sim] # the corresponding names
# Remove those who haven't tried Spinach yet (including Sera):
sim <- sim[ R[sim, "Spinach"]>0 ]
dimnames(R)[[1]][sim]
# aggregate the Spinach ratings of the K most similar people:
mean(R[sim[1:K], "Spinach"])
```



### Item-Based Collaborative Filtering

---

**Item-based** schemes rely on pairwise comparisons between the items
(columns in $R$). Hence, a similarity degree between the $i$-th and the $j$-th
item is given by:


\[
s^I_{i,j} = S(\mathbf{r}_{\cdot,i},\mathbf{r}_{\cdot,j}).
\]



```{R}
SI <- matrix(0, nrow=ncol(R), ncol=ncol(R),
    dimnames=dimnames(R)[c(2,2)]) # an empty n*n matrix
for (i in 1:ncol(R)) {
    for (j in 1:ncol(R)) {
        SI[i,j] <- cosim(R[,i], R[,j])
    }
}
```

---

```{R}
round(SI, 2)
```


---

In order to obtain the previously unobserved
rating $\hat{r}_{u,i}$ using the item-based approach, we typically
look for the $K$ most similar items and aggregate their corresponding
scores (for some $K\ge 1$)

> More formally, let $\{I_{j_1},\dots,I_{j_K}\}\in\mathcal{I}\setminus\{I_i\}$ be the set
    of items maximising $s^I_{i, j_1}, \dots, s^I_{i, j_K}$ and having $r_{u, j_1},\dots,r_{u, j_K}>0$.
    Then    \[
    \hat{r}_{u,i} = \frac{1}{K} \sum_{\ell=1}^K r_{u, j_\ell}.
    \]

> The arithmetic mean can be replaced with, e.g.,
a weighted arithmetic mean where weights are proportional to $s^I_{i, j_\ell}$
or the mode.



---


```{R}
K <- 2
(sim <- order(SI["Apple",],decreasing=TRUE))
# sim gives the indexes of items in decreasing order
# of similarity to Apple:
dimnames(R)[[2]][sim] # the corresponding item types
# Remove these which Sera haven't tried yet (e.g.,Apples):
sim <- sim[ R["Sera", sim]>0 ]
dimnames(R)[[2]][sim]
# aggregate Sera's ratings of the K most similar items:
mean(R["Sera", sim[1:K]])
```




## MovieLens Dataset (\*)

### Dataset

---

Let us make a few recommendations based on the MovieLens-9/2018-Small
dataset available at
https://grouplens.org/datasets/movielens/latest/

The dataset consists of
ca. 100,000 ratings to 9,000 movies by 600 users. Last updated 9/2018.

This is already a pretty large dataset! We might run into problems
with memory usage and run-time.

The following examples are a bit more difficult to follow
(programming-wise), therefore
we mark them with (\*).


See also https://movielens.org/ and [@movielens].



---


```{r,cache=TRUE}
options(stringsAsFactors=FALSE)
movies <- read.csv("datasets/ml-9-2018-small/movies.csv")
head(movies, 4)
nrow(movies)
```

---


```{r,cache=TRUE}
ratings <- read.csv("datasets/ml-9-2018-small/ratings.csv")
head(ratings, 4)
nrow(ratings)
table(ratings$rating)
```


### Data Cleansing

---

`movieId`s should be re-encoded, as not every film is mentioned/rated in the database.
We will re-map the `movieId`s to consecutive integers.

```{r,cache=TRUE}
movieId2 <- unique(ratings$movieId) # the list of all rated movieIds
(m <- max(ratings$userId)) # max user Id (these could've been cleaned up too)]
(n <- length(movieId2)) # number of unique movies
movies <- movies[movies$movieId %in% movieId2, ] # remove unrated movies
# we shall map movieId2[i] to i for each i=1,...,n
movies$movieId  <- match(movies$movieId, movieId2)
ratings$movieId <- match(ratings$movieId, movieId2)
# order the movies by the new movieId so that
# the movie with Id=i is at the i-th row.
movies <- movies[order(movies$movieId),]
stopifnot(all(movies$movieId == 1:n)) # sanity check
```




---

We will use a sparse matrix data type (from R package `Matrix`)
to store ratings data. We do not want to run out of memory!

> Sparse == many zeros.

```{r,cache=TRUE}
library("Matrix")
RML <- Matrix(0.0, sparse=TRUE, nrow=m, ncol=n)
# This is a vectorised operation;
# it is faster than a for loop over each row in ratings:
RML[cbind(ratings$userId, ratings$movieId)] <- ratings$rating
```


<!--# Not every movie is rated - removing:
RML <- RML[,apply(RML,2,sum)>0]
# Not each user gave a rating - removing:
RML <- RML[apply(RML,1,sum)>0,]-->

---

```{r,cache=TRUE}
# Preview:
RML[1:6, 1:18]
```


### Item-item Similarities

---

To recall, the cosine similarity between $\mathbf{a},\mathbf{b}\in\mathbb{R}^m$
is given by:

\[
S_C(\mathbf{a},\mathbf{b}) = \frac{ \sum_{i=1}^m a_i b_i
    }{
    \sqrt{ \sum_{i=1}^m a_i^2 }
    \sqrt{ \sum_{i=1}^m b_i^2 }
    }
    \]

In vector/matrix algebra notation (have you noticed this
section is marked with (\*)?), this is:

\[
S_C(\mathbf{a},\mathbf{b}) = \frac{\mathbf{a}^T \mathbf{b}}{
\sqrt{{\mathbf{a}^T \mathbf{a}}} \sqrt{{\mathbf{b}^T \mathbf{b}}}
}
\]

If $\mathbf{A}\in\mathbb{R}^{m\times n}$
we can "almost" compute the all the $n$ cosine similarities at once by applying:

\[
S_C(\mathbf{a},\mathbf{B}) = \frac{\mathbf{A}^T \mathbf{A}}{
\dots
}
\]

---

Cosine item-item similarities:

```{r,cache=TRUE}
norms <- as.matrix(sqrt(colSums(RML^2)))
RMLx <- as.matrix(crossprod(RML, RML))
SI <- RMLx/tcrossprod(norms)
SI[is.nan(SI)] <- 0 # there were some divisions by zero
```

`crossprod(A,B)` gives $\mathbf{A}^T \mathbf{B}$

`tcrossprod(A,B)` gives $\mathbf{A} \mathbf{B}^T$


### Example Recommendations

---

```{r,cache=TRUE}
recommend <- function(i, K, SI, movies) {
    # get K most similar movies to the i-th one
    ms <- order(SI[i,], decreasing=TRUE)
    tibble::tibble(
        Title=movies$title[ms[1:K]],
        SIC=SI[i,ms[1:K]])
}
```


---

```{r,cache=TRUE}
recommend(1215, 10, SI, movies)
```

---

```{r,cache=TRUE}
recommend(1, 10, SI, movies)
```

...and so on.


### Clustering

---

A cosine similarity matrix can be turned into a dissimilarity matrix:

```{r,cache=TRUE}
DI <- 1.0-SI
DI[DI<0] <- 0.0 # account for numeric inaccuracies
DI <- as.dist(DI)
```

Which enables us to perform, e.g., the cluster analysis of items:

```{r,cache=TRUE}
library("genie")
h <- hclust2(DI)
c <- cutree(h, k=20)
```

---


Example movies in the 3rd cluster:

```{r,cache=TRUE}
cat(i, strwrap(paste(head(movies$title[c==3], 20), collapse=", ")), sep="\n")
```



---


Example movies in the 5th cluster:

```{r,cache=TRUE}
cat(i, strwrap(paste(head(movies$title[c==5], 20), collapse=", ")), sep="\n")
```





## Outro

### Remarks

---

Good recommender systems are perfect tools to increase the revenue
of any user-centric enterprise.

Not a single algorithm, but an ensemble (a proper combination) of different approaches
is often used in practice, see the Further Reading section below for the detailed
information of the Netflix Prize winners.

Recommender systems are an interesting fusion of the techniques we
have already studied -- linear models, $K$-nearest neighbours etc.

### Issues

---

Building recommender systems is challenging, because
data is large yet often sparse;

> Here is the ratio of available ratings
vs. all possible user-item valuations for the Netflix Prize
(obviously, it is just a sample of
the complete data set that Netflix has):

```{r}
100480507/(480189*17770)
```

*Sparse matrix* (many "zeros" = unassigned ratings) data structure is
often used for storing of and computing over such data  effectively.

---

Some users are *biased* in the sense that they are more critical or enthusiastic than
average users.

> Is 3 stars a "bad", "fair enough" or "good" rating for you?
> Would you go to a bar/restaurant ranked 3.0 by the  Google Maps community?

It is particularly challenging to predict the preferences of users
that cast few ratings, e.g., those who just signed up (*the cold start problem*).



---



"Hill  et  al.  [1995]  have  shown  that  users  provide  inconsistent  ratings  when  asked  to  rate  the  same  movie  at  different  times.  They suggest that an algorithm cannot be more accurate than the variance in a user’s ratings for the same item." [@herlocker_etal: p. 6]

It is good to take the temporal characteristics of data
as well as external knowledge
into account (e.g., how long ago a rating was cast,
what is a film's genre).

The presented approaches are vulnerable to attacks -- bots may be used
to promote or inhibit selected items.





### Further Reading

#### {.allowframebreaks .unnumbered}

Recommended further reading:

- [@herlocker_etal]
- [@ricci_etal]
- [@lu_etal]
- [@movielens]

Other:

- [@bellkor_netflix]
- [@bigchaos_netflix]
- [@pragmatictheory_netflix]

Also don't forget to take a look at the R package `recommenderlab` (amongst others).

