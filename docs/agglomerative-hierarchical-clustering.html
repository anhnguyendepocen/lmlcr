<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2 Agglomerative Hierarchical Clustering | Lightweight Machine Learning Classics with R</title>
  <meta name="description" content="Explore some of the most fundamental algorithms which have stood the test of time and provide the basis for innovative solutions in data-driven AI. Learn how to use the R language for implementing various stages of data processing and modelling activities. Appreciate mathematics as the universal language for formalising data-intense problems and communicating their solutions. The book is for you if you’re yet to be fluent with university-level linear algebra, calculus and probability theory or you’ve forgotten all the maths you’ve ever learned, and are seeking a gentle, yet thorough, introduction to the topic." />
  <meta name="generator" content="bookdown 0.19 and GitBook 2.6.7" />

  <meta property="og:title" content="2 Agglomerative Hierarchical Clustering | Lightweight Machine Learning Classics with R" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://lmlcr.gagolewski.com" />
  
  <meta property="og:description" content="Explore some of the most fundamental algorithms which have stood the test of time and provide the basis for innovative solutions in data-driven AI. Learn how to use the R language for implementing various stages of data processing and modelling activities. Appreciate mathematics as the universal language for formalising data-intense problems and communicating their solutions. The book is for you if you’re yet to be fluent with university-level linear algebra, calculus and probability theory or you’ve forgotten all the maths you’ve ever learned, and are seeking a gentle, yet thorough, introduction to the topic." />
  <meta name="github-repo" content="gagolews/lmlcr" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2 Agglomerative Hierarchical Clustering | Lightweight Machine Learning Classics with R" />
  
  <meta name="twitter:description" content="Explore some of the most fundamental algorithms which have stood the test of time and provide the basis for innovative solutions in data-driven AI. Learn how to use the R language for implementing various stages of data processing and modelling activities. Appreciate mathematics as the universal language for formalising data-intense problems and communicating their solutions. The book is for you if you’re yet to be fluent with university-level linear algebra, calculus and probability theory or you’ve forgotten all the maths you’ve ever learned, and are seeking a gentle, yet thorough, introduction to the topic." />
  

<meta name="author" content="Marek Gagolewski" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="introduction.html"/>
<link rel="next" href="classification-and-regression-with-k-nearest-neighbours.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<style type="text/css">
div.exercise {
    font-style: italic;
    border-left: 2px solid gray;
    padding-left: 1em;
}

details.solution {
    border-left: 2px solid #ff8888;
    padding-left: 1em;
    margin-bottom: 2em;
}

</style>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li style='font-style: italic' ><a href="./">LMLCR</a></li>
<li style='font-size: smaller' ><a href="https://www.gagolewski.com">Marek Gagolewski</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#what-is-machine-learning"><i class="fa fa-check"></i><b>1.1</b> What is Machine Learning?</a><ul>
<li class="chapter" data-level="1.1.1" data-path="introduction.html"><a href="introduction.html#data-sources"><i class="fa fa-check"></i><b>1.1.1</b> Data Sources</a></li>
<li class="chapter" data-level="1.1.2" data-path="introduction.html"><a href="introduction.html#main-types-of-machine-learning-problems"><i class="fa fa-check"></i><b>1.1.2</b> Main Types of Machine Learning Problems</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#input-data-formalism"><i class="fa fa-check"></i><b>1.2</b> Input Data – Formalism</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#unsupervised-learning"><i class="fa fa-check"></i><b>1.3</b> Unsupervised Learning</a><ul>
<li class="chapter" data-level="1.3.1" data-path="introduction.html"><a href="introduction.html#main-types-of-unsupervised-learning-problems"><i class="fa fa-check"></i><b>1.3.1</b> Main Types of Unsupervised Learning Problems</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#supervised-learning"><i class="fa fa-check"></i><b>1.4</b> Supervised Learning</a><ul>
<li class="chapter" data-level="1.4.1" data-path="introduction.html"><a href="introduction.html#desired-outputs"><i class="fa fa-check"></i><b>1.4.1</b> Desired Outputs</a></li>
<li class="chapter" data-level="1.4.2" data-path="introduction.html"><a href="introduction.html#types-of-supervised-learning-problems"><i class="fa fa-check"></i><b>1.4.2</b> Types of Supervised Learning Problems</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="agglomerative-hierarchical-clustering.html"><a href="agglomerative-hierarchical-clustering.html"><i class="fa fa-check"></i><b>2</b> Agglomerative Hierarchical Clustering</a><ul>
<li class="chapter" data-level="2.1" data-path="agglomerative-hierarchical-clustering.html"><a href="agglomerative-hierarchical-clustering.html#agglomerative-hierarchical-clustering-1"><i class="fa fa-check"></i><b>2.1</b> Agglomerative Hierarchical Clustering</a><ul>
<li class="chapter" data-level="2.1.1" data-path="agglomerative-hierarchical-clustering.html"><a href="agglomerative-hierarchical-clustering.html#introduction-1"><i class="fa fa-check"></i><b>2.1.1</b> Introduction</a></li>
<li class="chapter" data-level="2.1.2" data-path="agglomerative-hierarchical-clustering.html"><a href="agglomerative-hierarchical-clustering.html#example-in-r"><i class="fa fa-check"></i><b>2.1.2</b> Example in R</a></li>
<li class="chapter" data-level="2.1.3" data-path="agglomerative-hierarchical-clustering.html"><a href="agglomerative-hierarchical-clustering.html#linkage-functions"><i class="fa fa-check"></i><b>2.1.3</b> Linkage Functions</a></li>
<li class="chapter" data-level="2.1.4" data-path="agglomerative-hierarchical-clustering.html"><a href="agglomerative-hierarchical-clustering.html#cluster-dendrograms"><i class="fa fa-check"></i><b>2.1.4</b> Cluster Dendrograms</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="agglomerative-hierarchical-clustering.html"><a href="agglomerative-hierarchical-clustering.html#exercises"><i class="fa fa-check"></i><b>2.2</b> Exercises</a></li>
<li class="chapter" data-level="2.3" data-path="agglomerative-hierarchical-clustering.html"><a href="agglomerative-hierarchical-clustering.html#outro"><i class="fa fa-check"></i><b>2.3</b> Outro</a><ul>
<li class="chapter" data-level="2.3.1" data-path="agglomerative-hierarchical-clustering.html"><a href="agglomerative-hierarchical-clustering.html#remarks"><i class="fa fa-check"></i><b>2.3.1</b> Remarks</a></li>
<li class="chapter" data-level="2.3.2" data-path="agglomerative-hierarchical-clustering.html"><a href="agglomerative-hierarchical-clustering.html#further-reading"><i class="fa fa-check"></i><b>2.3.2</b> Further Reading</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="classification-and-regression-with-k-nearest-neighbours.html"><a href="classification-and-regression-with-k-nearest-neighbours.html"><i class="fa fa-check"></i><b>3</b> Classification and Regression with K-Nearest Neighbours</a><ul>
<li class="chapter" data-level="3.1" data-path="classification-and-regression-with-k-nearest-neighbours.html"><a href="classification-and-regression-with-k-nearest-neighbours.html#introduction-2"><i class="fa fa-check"></i><b>3.1</b> Introduction</a><ul>
<li class="chapter" data-level="3.1.1" data-path="classification-and-regression-with-k-nearest-neighbours.html"><a href="classification-and-regression-with-k-nearest-neighbours.html#classification-task"><i class="fa fa-check"></i><b>3.1.1</b> Classification Task</a></li>
<li class="chapter" data-level="3.1.2" data-path="classification-and-regression-with-k-nearest-neighbours.html"><a href="classification-and-regression-with-k-nearest-neighbours.html#data"><i class="fa fa-check"></i><b>3.1.2</b> Data</a></li>
<li class="chapter" data-level="3.1.3" data-path="classification-and-regression-with-k-nearest-neighbours.html"><a href="classification-and-regression-with-k-nearest-neighbours.html#training-and-test-sets"><i class="fa fa-check"></i><b>3.1.3</b> Training and Test Sets</a></li>
<li class="chapter" data-level="3.1.4" data-path="classification-and-regression-with-k-nearest-neighbours.html"><a href="classification-and-regression-with-k-nearest-neighbours.html#discussed-methods"><i class="fa fa-check"></i><b>3.1.4</b> Discussed Methods</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="classification-and-regression-with-k-nearest-neighbours.html"><a href="classification-and-regression-with-k-nearest-neighbours.html#k-nearest-neighbour-classifier"><i class="fa fa-check"></i><b>3.2</b> K-nearest Neighbour Classifier</a><ul>
<li class="chapter" data-level="3.2.1" data-path="classification-and-regression-with-k-nearest-neighbours.html"><a href="classification-and-regression-with-k-nearest-neighbours.html#introduction-3"><i class="fa fa-check"></i><b>3.2.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2.2" data-path="classification-and-regression-with-k-nearest-neighbours.html"><a href="classification-and-regression-with-k-nearest-neighbours.html#example-in-r-1"><i class="fa fa-check"></i><b>3.2.2</b> Example in R</a></li>
<li class="chapter" data-level="3.2.3" data-path="classification-and-regression-with-k-nearest-neighbours.html"><a href="classification-and-regression-with-k-nearest-neighbours.html#feature-engineering"><i class="fa fa-check"></i><b>3.2.3</b> Feature Engineering</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="classification-and-regression-with-k-nearest-neighbours.html"><a href="classification-and-regression-with-k-nearest-neighbours.html#model-assessment-and-selection"><i class="fa fa-check"></i><b>3.3</b> Model Assessment and Selection</a><ul>
<li class="chapter" data-level="3.3.1" data-path="classification-and-regression-with-k-nearest-neighbours.html"><a href="classification-and-regression-with-k-nearest-neighbours.html#performance-metrics"><i class="fa fa-check"></i><b>3.3.1</b> Performance Metrics</a></li>
<li class="chapter" data-level="3.3.2" data-path="classification-and-regression-with-k-nearest-neighbours.html"><a href="classification-and-regression-with-k-nearest-neighbours.html#how-to-choose-k-for-k-nn-classification"><i class="fa fa-check"></i><b>3.3.2</b> How to Choose K for K-NN Classification?</a></li>
<li class="chapter" data-level="3.3.3" data-path="classification-and-regression-with-k-nearest-neighbours.html"><a href="classification-and-regression-with-k-nearest-neighbours.html#training-validation-and-test-sets"><i class="fa fa-check"></i><b>3.3.3</b> Training, Validation and Test sets</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="classification-and-regression-with-k-nearest-neighbours.html"><a href="classification-and-regression-with-k-nearest-neighbours.html#implementing-a-k-nn-classifier"><i class="fa fa-check"></i><b>3.4</b> Implementing a K-NN Classifier (*)</a><ul>
<li class="chapter" data-level="3.4.1" data-path="classification-and-regression-with-k-nearest-neighbours.html"><a href="classification-and-regression-with-k-nearest-neighbours.html#factor-data-type"><i class="fa fa-check"></i><b>3.4.1</b> Factor Data Type</a></li>
<li class="chapter" data-level="3.4.2" data-path="classification-and-regression-with-k-nearest-neighbours.html"><a href="classification-and-regression-with-k-nearest-neighbours.html#main-routine"><i class="fa fa-check"></i><b>3.4.2</b> Main Routine (*)</a></li>
<li class="chapter" data-level="3.4.3" data-path="classification-and-regression-with-k-nearest-neighbours.html"><a href="classification-and-regression-with-k-nearest-neighbours.html#mode"><i class="fa fa-check"></i><b>3.4.3</b> Mode</a></li>
<li class="chapter" data-level="3.4.4" data-path="classification-and-regression-with-k-nearest-neighbours.html"><a href="classification-and-regression-with-k-nearest-neighbours.html#nn-search-routines"><i class="fa fa-check"></i><b>3.4.4</b> NN Search Routines (*)</a></li>
<li class="chapter" data-level="3.4.5" data-path="classification-and-regression-with-k-nearest-neighbours.html"><a href="classification-and-regression-with-k-nearest-neighbours.html#different-metrics"><i class="fa fa-check"></i><b>3.4.5</b> Different Metrics (*)</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="classification-and-regression-with-k-nearest-neighbours.html"><a href="classification-and-regression-with-k-nearest-neighbours.html#exercises-1"><i class="fa fa-check"></i><b>3.5</b> Exercises</a><ul>
<li class="chapter" data-level="3.5.1" data-path="classification-and-regression-with-k-nearest-neighbours.html"><a href="classification-and-regression-with-k-nearest-neighbours.html#wine-quality-best-k-nn-parameters-via-cross-validation"><i class="fa fa-check"></i><b>3.5.1</b> Wine Quality – Best K-NN Parameters via Cross-Validation (*)</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="classification-and-regression-with-k-nearest-neighbours.html"><a href="classification-and-regression-with-k-nearest-neighbours.html#outro-1"><i class="fa fa-check"></i><b>3.6</b> Outro</a><ul>
<li class="chapter" data-level="3.6.1" data-path="classification-and-regression-with-k-nearest-neighbours.html"><a href="classification-and-regression-with-k-nearest-neighbours.html#remarks-1"><i class="fa fa-check"></i><b>3.6.1</b> Remarks</a></li>
<li class="chapter" data-level="3.6.2" data-path="classification-and-regression-with-k-nearest-neighbours.html"><a href="classification-and-regression-with-k-nearest-neighbours.html#side-note-k-nn-regression"><i class="fa fa-check"></i><b>3.6.2</b> Side Note: K-NN Regression</a></li>
<li class="chapter" data-level="3.6.3" data-path="classification-and-regression-with-k-nearest-neighbours.html"><a href="classification-and-regression-with-k-nearest-neighbours.html#further-reading-1"><i class="fa fa-check"></i><b>3.6.3</b> Further Reading</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="decision-and-regression-trees.html"><a href="decision-and-regression-trees.html"><i class="fa fa-check"></i><b>4</b> Decision and Regression Trees</a><ul>
<li class="chapter" data-level="4.1" data-path="decision-and-regression-trees.html"><a href="decision-and-regression-trees.html#introduction-4"><i class="fa fa-check"></i><b>4.1</b> Introduction</a><ul>
<li class="chapter" data-level="4.1.1" data-path="decision-and-regression-trees.html"><a href="decision-and-regression-trees.html#classification-task-1"><i class="fa fa-check"></i><b>4.1.1</b> Classification Task</a></li>
<li class="chapter" data-level="4.1.2" data-path="decision-and-regression-trees.html"><a href="decision-and-regression-trees.html#data-1"><i class="fa fa-check"></i><b>4.1.2</b> Data</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="decision-and-regression-trees.html"><a href="decision-and-regression-trees.html#decision-trees"><i class="fa fa-check"></i><b>4.2</b> Decision Trees</a><ul>
<li class="chapter" data-level="4.2.1" data-path="decision-and-regression-trees.html"><a href="decision-and-regression-trees.html#introduction-5"><i class="fa fa-check"></i><b>4.2.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2.2" data-path="decision-and-regression-trees.html"><a href="decision-and-regression-trees.html#example-in-r-2"><i class="fa fa-check"></i><b>4.2.2</b> Example in R</a></li>
<li class="chapter" data-level="4.2.3" data-path="decision-and-regression-trees.html"><a href="decision-and-regression-trees.html#a-note-on-decision-tree-learning"><i class="fa fa-check"></i><b>4.2.3</b> A Note on Decision Tree Learning</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="decision-and-regression-trees.html"><a href="decision-and-regression-trees.html#exercises-2"><i class="fa fa-check"></i><b>4.3</b> Exercises</a><ul>
<li class="chapter" data-level="4.3.1" data-path="decision-and-regression-trees.html"><a href="decision-and-regression-trees.html#edstats-where-girls-are-better-at-maths-than-boys"><i class="fa fa-check"></i><b>4.3.1</b> EdStats – Where Girls Are Better at Maths Than Boys?</a></li>
<li class="chapter" data-level="4.3.2" data-path="decision-and-regression-trees.html"><a href="decision-and-regression-trees.html#edstats-and-world-factbook-joining-forces"><i class="fa fa-check"></i><b>4.3.2</b> EdStats and World Factbook – Joining Forces</a></li>
<li class="chapter" data-level="4.3.3" data-path="decision-and-regression-trees.html"><a href="decision-and-regression-trees.html#wine-quality-random-forest-and-xgboost"><i class="fa fa-check"></i><b>4.3.3</b> Wine Quality – Random Forest and XGBoost (*)</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="decision-and-regression-trees.html"><a href="decision-and-regression-trees.html#outro-2"><i class="fa fa-check"></i><b>4.4</b> Outro</a><ul>
<li class="chapter" data-level="4.4.1" data-path="decision-and-regression-trees.html"><a href="decision-and-regression-trees.html#remarks-2"><i class="fa fa-check"></i><b>4.4.1</b> Remarks</a></li>
<li class="chapter" data-level="4.4.2" data-path="decision-and-regression-trees.html"><a href="decision-and-regression-trees.html#further-reading-2"><i class="fa fa-check"></i><b>4.4.2</b> Further Reading</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>5</b> Simple Linear Regression</a><ul>
<li class="chapter" data-level="5.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#simple-regression"><i class="fa fa-check"></i><b>5.1</b> Simple Regression</a><ul>
<li class="chapter" data-level="5.1.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#introduction-6"><i class="fa fa-check"></i><b>5.1.1</b> Introduction</a></li>
<li class="chapter" data-level="5.1.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#search-space-and-objective"><i class="fa fa-check"></i><b>5.1.2</b> Search Space and Objective</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#simple-linear-regression-1"><i class="fa fa-check"></i><b>5.2</b> Simple Linear Regression</a><ul>
<li class="chapter" data-level="5.2.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#introduction-7"><i class="fa fa-check"></i><b>5.2.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#solution-in-r"><i class="fa fa-check"></i><b>5.2.2</b> Solution in R</a></li>
<li class="chapter" data-level="5.2.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#analytic-solution"><i class="fa fa-check"></i><b>5.2.3</b> Analytic Solution</a></li>
<li class="chapter" data-level="5.2.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#derivation-of-the-solution"><i class="fa fa-check"></i><b>5.2.4</b> Derivation of the Solution (**)</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#exercises-3"><i class="fa fa-check"></i><b>5.3</b> Exercises</a><ul>
<li class="chapter" data-level="5.3.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#the-anscombe-quartet"><i class="fa fa-check"></i><b>5.3.1</b> The Anscombe Quartet</a></li>
<li class="chapter" data-level="5.3.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#median-house-value-in-boston"><i class="fa fa-check"></i><b>5.3.2</b> Median House Value in Boston</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#outro-3"><i class="fa fa-check"></i><b>5.4</b> Outro</a><ul>
<li class="chapter" data-level="5.4.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#remarks-3"><i class="fa fa-check"></i><b>5.4.1</b> Remarks</a></li>
<li class="chapter" data-level="5.4.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#further-reading-3"><i class="fa fa-check"></i><b>5.4.2</b> Further Reading</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="multiple-regression.html"><a href="multiple-regression.html"><i class="fa fa-check"></i><b>6</b> Multiple Regression</a><ul>
<li class="chapter" data-level="6.1" data-path="multiple-regression.html"><a href="multiple-regression.html#introduction-8"><i class="fa fa-check"></i><b>6.1</b> Introduction</a><ul>
<li class="chapter" data-level="6.1.1" data-path="multiple-regression.html"><a href="multiple-regression.html#formalism"><i class="fa fa-check"></i><b>6.1.1</b> Formalism</a></li>
<li class="chapter" data-level="6.1.2" data-path="multiple-regression.html"><a href="multiple-regression.html#simple-linear-regression---recap"><i class="fa fa-check"></i><b>6.1.2</b> Simple Linear Regression - Recap</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="multiple-regression.html"><a href="multiple-regression.html#multiple-linear-regression"><i class="fa fa-check"></i><b>6.2</b> Multiple Linear Regression</a><ul>
<li class="chapter" data-level="6.2.1" data-path="multiple-regression.html"><a href="multiple-regression.html#problem-formulation"><i class="fa fa-check"></i><b>6.2.1</b> Problem Formulation</a></li>
<li class="chapter" data-level="6.2.2" data-path="multiple-regression.html"><a href="multiple-regression.html#fitting-a-linear-model-in-r"><i class="fa fa-check"></i><b>6.2.2</b> Fitting a Linear Model in R</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="multiple-regression.html"><a href="multiple-regression.html#finding-the-best-model"><i class="fa fa-check"></i><b>6.3</b> Finding the Best Model</a><ul>
<li class="chapter" data-level="6.3.1" data-path="multiple-regression.html"><a href="multiple-regression.html#model-diagnostics"><i class="fa fa-check"></i><b>6.3.1</b> Model Diagnostics</a></li>
<li class="chapter" data-level="6.3.2" data-path="multiple-regression.html"><a href="multiple-regression.html#variable-selection"><i class="fa fa-check"></i><b>6.3.2</b> Variable Selection</a></li>
<li class="chapter" data-level="6.3.3" data-path="multiple-regression.html"><a href="multiple-regression.html#variable-transformation"><i class="fa fa-check"></i><b>6.3.3</b> Variable Transformation</a></li>
<li class="chapter" data-level="6.3.4" data-path="multiple-regression.html"><a href="multiple-regression.html#predictive-vs.-descriptive-power"><i class="fa fa-check"></i><b>6.3.4</b> Predictive vs. Descriptive Power</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="multiple-regression.html"><a href="multiple-regression.html#exercises-4"><i class="fa fa-check"></i><b>6.4</b> Exercises</a><ul>
<li class="chapter" data-level="6.4.1" data-path="multiple-regression.html"><a href="multiple-regression.html#anscombes-quartet-revisited"><i class="fa fa-check"></i><b>6.4.1</b> Anscombe’s Quartet Revisited</a></li>
<li class="chapter" data-level="6.4.2" data-path="multiple-regression.html"><a href="multiple-regression.html#countries-of-the-world-simple-models-involving-the-gdp-per-capita"><i class="fa fa-check"></i><b>6.4.2</b> Countries of the World – Simple models involving the GDP per capita</a></li>
<li class="chapter" data-level="6.4.3" data-path="multiple-regression.html"><a href="multiple-regression.html#countries-of-the-world-most-correlated-variables"><i class="fa fa-check"></i><b>6.4.3</b> Countries of the World – Most correlated variables (*)</a></li>
<li class="chapter" data-level="6.4.4" data-path="multiple-regression.html"><a href="multiple-regression.html#countries-of-the-world-a-non-linear-model-based-on-the-gdp-per-capita"><i class="fa fa-check"></i><b>6.4.4</b> Countries of the World – A non-linear model based on the GDP per capita</a></li>
<li class="chapter" data-level="6.4.5" data-path="multiple-regression.html"><a href="multiple-regression.html#countries-of-the-world-a-multiple-regression-model-for-the-per-capita-gdp"><i class="fa fa-check"></i><b>6.4.5</b> Countries of the World – A multiple regression model for the per capita GDP</a></li>
<li class="chapter" data-level="6.4.6" data-path="multiple-regression.html"><a href="multiple-regression.html#median-house-value-in-boston-continued"><i class="fa fa-check"></i><b>6.4.6</b> Median House Value in Boston (Continued)</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="multiple-regression.html"><a href="multiple-regression.html#outro-4"><i class="fa fa-check"></i><b>6.5</b> Outro</a><ul>
<li class="chapter" data-level="6.5.1" data-path="multiple-regression.html"><a href="multiple-regression.html#remarks-4"><i class="fa fa-check"></i><b>6.5.1</b> Remarks</a></li>
<li class="chapter" data-level="6.5.2" data-path="multiple-regression.html"><a href="multiple-regression.html#other-methods-for-regression"><i class="fa fa-check"></i><b>6.5.2</b> Other Methods for Regression</a></li>
<li class="chapter" data-level="6.5.3" data-path="multiple-regression.html"><a href="multiple-regression.html#derivation-of-the-solution-1"><i class="fa fa-check"></i><b>6.5.3</b> Derivation of the Solution (**)</a></li>
<li class="chapter" data-level="6.5.4" data-path="multiple-regression.html"><a href="multiple-regression.html#solution-in-matrix-form"><i class="fa fa-check"></i><b>6.5.4</b> Solution in Matrix Form (***)</a></li>
<li class="chapter" data-level="6.5.5" data-path="multiple-regression.html"><a href="multiple-regression.html#pearsons-r-in-matrix-form"><i class="fa fa-check"></i><b>6.5.5</b> Pearson’s r in Matrix Form (**)</a></li>
<li class="chapter" data-level="6.5.6" data-path="multiple-regression.html"><a href="multiple-regression.html#further-reading-4"><i class="fa fa-check"></i><b>6.5.6</b> Further Reading</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="classification-with-linear-models.html"><a href="classification-with-linear-models.html"><i class="fa fa-check"></i><b>7</b> Classification with Linear Models</a><ul>
<li class="chapter" data-level="7.1" data-path="classification-with-linear-models.html"><a href="classification-with-linear-models.html#introduction-9"><i class="fa fa-check"></i><b>7.1</b> Introduction</a><ul>
<li class="chapter" data-level="7.1.1" data-path="classification-with-linear-models.html"><a href="classification-with-linear-models.html#classification-task-2"><i class="fa fa-check"></i><b>7.1.1</b> Classification Task</a></li>
<li class="chapter" data-level="7.1.2" data-path="classification-with-linear-models.html"><a href="classification-with-linear-models.html#data-2"><i class="fa fa-check"></i><b>7.1.2</b> Data</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="classification-with-linear-models.html"><a href="classification-with-linear-models.html#binary-logistic-regression"><i class="fa fa-check"></i><b>7.2</b> Binary Logistic Regression</a><ul>
<li class="chapter" data-level="7.2.1" data-path="classification-with-linear-models.html"><a href="classification-with-linear-models.html#motivation"><i class="fa fa-check"></i><b>7.2.1</b> Motivation</a></li>
<li class="chapter" data-level="7.2.2" data-path="classification-with-linear-models.html"><a href="classification-with-linear-models.html#logistic-model"><i class="fa fa-check"></i><b>7.2.2</b> Logistic Model</a></li>
<li class="chapter" data-level="7.2.3" data-path="classification-with-linear-models.html"><a href="classification-with-linear-models.html#example-in-r-3"><i class="fa fa-check"></i><b>7.2.3</b> Example in R</a></li>
<li class="chapter" data-level="7.2.4" data-path="classification-with-linear-models.html"><a href="classification-with-linear-models.html#loss-function-cross-entropy"><i class="fa fa-check"></i><b>7.2.4</b> Loss Function: Cross-entropy</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="classification-with-linear-models.html"><a href="classification-with-linear-models.html#exercises-5"><i class="fa fa-check"></i><b>7.3</b> Exercises</a><ul>
<li class="chapter" data-level="7.3.1" data-path="classification-with-linear-models.html"><a href="classification-with-linear-models.html#edstats-fitting-of-binary-logistic-regression-models"><i class="fa fa-check"></i><b>7.3.1</b> EdStats – Fitting of Binary Logistic Regression Models</a></li>
<li class="chapter" data-level="7.3.2" data-path="classification-with-linear-models.html"><a href="classification-with-linear-models.html#edstats-variable-selection-in-binary-logistic-regression"><i class="fa fa-check"></i><b>7.3.2</b> EdStats – Variable Selection in Binary Logistic Regression (*)</a></li>
<li class="chapter" data-level="7.3.3" data-path="classification-with-linear-models.html"><a href="classification-with-linear-models.html#currency-exchange-rates-growthfall"><i class="fa fa-check"></i><b>7.3.3</b> Currency Exchange Rates Growth/Fall</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="classification-with-linear-models.html"><a href="classification-with-linear-models.html#outro-5"><i class="fa fa-check"></i><b>7.4</b> Outro</a><ul>
<li class="chapter" data-level="7.4.1" data-path="classification-with-linear-models.html"><a href="classification-with-linear-models.html#remarks-5"><i class="fa fa-check"></i><b>7.4.1</b> Remarks</a></li>
<li class="chapter" data-level="7.4.2" data-path="classification-with-linear-models.html"><a href="classification-with-linear-models.html#further-reading-5"><i class="fa fa-check"></i><b>7.4.2</b> Further Reading</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="continuous-optimisation-with-iterative-algorithms.html"><a href="continuous-optimisation-with-iterative-algorithms.html"><i class="fa fa-check"></i><b>8</b> Continuous Optimisation with Iterative Algorithms</a><ul>
<li class="chapter" data-level="8.1" data-path="continuous-optimisation-with-iterative-algorithms.html"><a href="continuous-optimisation-with-iterative-algorithms.html#introduction-10"><i class="fa fa-check"></i><b>8.1</b> Introduction</a><ul>
<li class="chapter" data-level="8.1.1" data-path="continuous-optimisation-with-iterative-algorithms.html"><a href="continuous-optimisation-with-iterative-algorithms.html#optimisation-problems"><i class="fa fa-check"></i><b>8.1.1</b> Optimisation Problems</a></li>
<li class="chapter" data-level="8.1.2" data-path="continuous-optimisation-with-iterative-algorithms.html"><a href="continuous-optimisation-with-iterative-algorithms.html#types-of-minima-and-maxima"><i class="fa fa-check"></i><b>8.1.2</b> Types of Minima and Maxima</a></li>
<li class="chapter" data-level="8.1.3" data-path="continuous-optimisation-with-iterative-algorithms.html"><a href="continuous-optimisation-with-iterative-algorithms.html#example-objective-over-a-2d-domain"><i class="fa fa-check"></i><b>8.1.3</b> Example Objective over a 2D Domain</a></li>
<li class="chapter" data-level="8.1.4" data-path="continuous-optimisation-with-iterative-algorithms.html"><a href="continuous-optimisation-with-iterative-algorithms.html#example-optimisation-problems-in-machine-learning"><i class="fa fa-check"></i><b>8.1.4</b> Example Optimisation Problems in Machine Learning</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="continuous-optimisation-with-iterative-algorithms.html"><a href="continuous-optimisation-with-iterative-algorithms.html#iterative-methods"><i class="fa fa-check"></i><b>8.2</b> Iterative Methods</a><ul>
<li class="chapter" data-level="8.2.1" data-path="continuous-optimisation-with-iterative-algorithms.html"><a href="continuous-optimisation-with-iterative-algorithms.html#introduction-11"><i class="fa fa-check"></i><b>8.2.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2.2" data-path="continuous-optimisation-with-iterative-algorithms.html"><a href="continuous-optimisation-with-iterative-algorithms.html#example-in-r-4"><i class="fa fa-check"></i><b>8.2.2</b> Example in R</a></li>
<li class="chapter" data-level="8.2.3" data-path="continuous-optimisation-with-iterative-algorithms.html"><a href="continuous-optimisation-with-iterative-algorithms.html#convergence-to-local-optima"><i class="fa fa-check"></i><b>8.2.3</b> Convergence to Local Optima</a></li>
<li class="chapter" data-level="8.2.4" data-path="continuous-optimisation-with-iterative-algorithms.html"><a href="continuous-optimisation-with-iterative-algorithms.html#random-restarts"><i class="fa fa-check"></i><b>8.2.4</b> Random Restarts</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="continuous-optimisation-with-iterative-algorithms.html"><a href="continuous-optimisation-with-iterative-algorithms.html#gradient-descent"><i class="fa fa-check"></i><b>8.3</b> Gradient Descent</a><ul>
<li class="chapter" data-level="8.3.1" data-path="continuous-optimisation-with-iterative-algorithms.html"><a href="continuous-optimisation-with-iterative-algorithms.html#function-gradient"><i class="fa fa-check"></i><b>8.3.1</b> Function Gradient (*)</a></li>
<li class="chapter" data-level="8.3.2" data-path="continuous-optimisation-with-iterative-algorithms.html"><a href="continuous-optimisation-with-iterative-algorithms.html#three-facts-on-the-gradient"><i class="fa fa-check"></i><b>8.3.2</b> Three Facts on the Gradient</a></li>
<li class="chapter" data-level="8.3.3" data-path="continuous-optimisation-with-iterative-algorithms.html"><a href="continuous-optimisation-with-iterative-algorithms.html#gradient-descent-algorithm-gd"><i class="fa fa-check"></i><b>8.3.3</b> Gradient Descent Algorithm (GD)</a></li>
<li class="chapter" data-level="8.3.4" data-path="continuous-optimisation-with-iterative-algorithms.html"><a href="continuous-optimisation-with-iterative-algorithms.html#example-mnist"><i class="fa fa-check"></i><b>8.3.4</b> Example: MNIST (*)</a></li>
<li class="chapter" data-level="8.3.5" data-path="continuous-optimisation-with-iterative-algorithms.html"><a href="continuous-optimisation-with-iterative-algorithms.html#stochastic-gradient-descent-sgd"><i class="fa fa-check"></i><b>8.3.5</b> Stochastic Gradient Descent (SGD) (*)</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="continuous-optimisation-with-iterative-algorithms.html"><a href="continuous-optimisation-with-iterative-algorithms.html#a-note-on-convex-optimisation"><i class="fa fa-check"></i><b>8.4</b> A Note on Convex Optimisation (*)</a></li>
<li class="chapter" data-level="8.5" data-path="continuous-optimisation-with-iterative-algorithms.html"><a href="continuous-optimisation-with-iterative-algorithms.html#outro-6"><i class="fa fa-check"></i><b>8.5</b> Outro</a><ul>
<li class="chapter" data-level="8.5.1" data-path="continuous-optimisation-with-iterative-algorithms.html"><a href="continuous-optimisation-with-iterative-algorithms.html#remarks-6"><i class="fa fa-check"></i><b>8.5.1</b> Remarks</a></li>
<li class="chapter" data-level="8.5.2" data-path="continuous-optimisation-with-iterative-algorithms.html"><a href="continuous-optimisation-with-iterative-algorithms.html#further-reading-6"><i class="fa fa-check"></i><b>8.5.2</b> Further Reading</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="clustering-with-k-means.html"><a href="clustering-with-k-means.html"><i class="fa fa-check"></i><b>9</b> Clustering with K-Means</a><ul>
<li class="chapter" data-level="9.1" data-path="clustering-with-k-means.html"><a href="clustering-with-k-means.html#k-means-clustering"><i class="fa fa-check"></i><b>9.1</b> K-means Clustering</a><ul>
<li class="chapter" data-level="9.1.1" data-path="clustering-with-k-means.html"><a href="clustering-with-k-means.html#example-in-r-5"><i class="fa fa-check"></i><b>9.1.1</b> Example in R</a></li>
<li class="chapter" data-level="9.1.2" data-path="clustering-with-k-means.html"><a href="clustering-with-k-means.html#problem-statement"><i class="fa fa-check"></i><b>9.1.2</b> Problem Statement</a></li>
<li class="chapter" data-level="9.1.3" data-path="clustering-with-k-means.html"><a href="clustering-with-k-means.html#algorithms-for-the-k-means-problem"><i class="fa fa-check"></i><b>9.1.3</b> Algorithms for the K-means Problem</a></li>
<li class="chapter" data-level="9.1.4" data-path="clustering-with-k-means.html"><a href="clustering-with-k-means.html#k-means-revisited"><i class="fa fa-check"></i><b>9.1.4</b> K-means Revisited</a></li>
<li class="chapter" data-level="9.1.5" data-path="clustering-with-k-means.html"><a href="clustering-with-k-means.html#optim-vs.-kmeans"><i class="fa fa-check"></i><b>9.1.5</b> optim() vs. kmeans()</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="clustering-with-k-means.html"><a href="clustering-with-k-means.html#exercises-6"><i class="fa fa-check"></i><b>9.2</b> Exercises</a><ul>
<li class="chapter" data-level="9.2.1" data-path="clustering-with-k-means.html"><a href="clustering-with-k-means.html#clustering-of-the-world-factbook"><i class="fa fa-check"></i><b>9.2.1</b> Clustering of the World Factbook</a></li>
<li class="chapter" data-level="9.2.2" data-path="clustering-with-k-means.html"><a href="clustering-with-k-means.html#unbalance-dataset-k-means-needs-multiple-starts"><i class="fa fa-check"></i><b>9.2.2</b> Unbalance Dataset – K-Means Needs Multiple Starts</a></li>
<li class="chapter" data-level="9.2.3" data-path="clustering-with-k-means.html"><a href="clustering-with-k-means.html#clustering-of-typical-2d-benchmark-datasets"><i class="fa fa-check"></i><b>9.2.3</b> Clustering of Typical 2D Benchmark Datasets</a></li>
<li class="chapter" data-level="9.2.4" data-path="clustering-with-k-means.html"><a href="clustering-with-k-means.html#wine-quality-volatile.acidity-and-sulphates"><i class="fa fa-check"></i><b>9.2.4</b> Wine Quality – <code>volatile.acidity</code> and <code>sulphates</code></a></li>
<li class="chapter" data-level="9.2.5" data-path="clustering-with-k-means.html"><a href="clustering-with-k-means.html#wine-quality-chlorides-and-total.sulfur.dioxide"><i class="fa fa-check"></i><b>9.2.5</b> Wine Quality – <code>chlorides</code> and <code>total.sulfur.dioxide</code></a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="clustering-with-k-means.html"><a href="clustering-with-k-means.html#outro-7"><i class="fa fa-check"></i><b>9.3</b> Outro</a><ul>
<li class="chapter" data-level="9.3.1" data-path="clustering-with-k-means.html"><a href="clustering-with-k-means.html#remarks-7"><i class="fa fa-check"></i><b>9.3.1</b> Remarks</a></li>
<li class="chapter" data-level="9.3.2" data-path="clustering-with-k-means.html"><a href="clustering-with-k-means.html#further-reading-7"><i class="fa fa-check"></i><b>9.3.2</b> Further Reading</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="discrete-optimisation.html"><a href="discrete-optimisation.html"><i class="fa fa-check"></i><b>10</b> Discrete Optimisation</a><ul>
<li class="chapter" data-level="10.1" data-path="discrete-optimisation.html"><a href="discrete-optimisation.html#introduction-12"><i class="fa fa-check"></i><b>10.1</b> Introduction</a><ul>
<li class="chapter" data-level="10.1.1" data-path="discrete-optimisation.html"><a href="discrete-optimisation.html#recap"><i class="fa fa-check"></i><b>10.1.1</b> Recap</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="discrete-optimisation.html"><a href="discrete-optimisation.html#outro-8"><i class="fa fa-check"></i><b>10.2</b> Outro</a><ul>
<li class="chapter" data-level="10.2.1" data-path="discrete-optimisation.html"><a href="discrete-optimisation.html#remarks-8"><i class="fa fa-check"></i><b>10.2.1</b> Remarks</a></li>
<li class="chapter" data-level="10.2.2" data-path="discrete-optimisation.html"><a href="discrete-optimisation.html#further-reading-8"><i class="fa fa-check"></i><b>10.2.2</b> Further Reading</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="shallow-and-deep-neural-networks.html"><a href="shallow-and-deep-neural-networks.html"><i class="fa fa-check"></i><b>11</b> Shallow and Deep Neural Networks</a><ul>
<li class="chapter" data-level="11.1" data-path="shallow-and-deep-neural-networks.html"><a href="shallow-and-deep-neural-networks.html#introduction-13"><i class="fa fa-check"></i><b>11.1</b> Introduction</a><ul>
<li class="chapter" data-level="11.1.1" data-path="shallow-and-deep-neural-networks.html"><a href="shallow-and-deep-neural-networks.html#binary-logistic-regression-recap"><i class="fa fa-check"></i><b>11.1.1</b> Binary Logistic Regression: Recap</a></li>
<li class="chapter" data-level="11.1.2" data-path="shallow-and-deep-neural-networks.html"><a href="shallow-and-deep-neural-networks.html#data-3"><i class="fa fa-check"></i><b>11.1.2</b> Data</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="shallow-and-deep-neural-networks.html"><a href="shallow-and-deep-neural-networks.html#multinomial-logistic-regression"><i class="fa fa-check"></i><b>11.2</b> Multinomial Logistic Regression</a><ul>
<li class="chapter" data-level="11.2.1" data-path="shallow-and-deep-neural-networks.html"><a href="shallow-and-deep-neural-networks.html#a-note-on-data-representation"><i class="fa fa-check"></i><b>11.2.1</b> A Note on Data Representation</a></li>
<li class="chapter" data-level="11.2.2" data-path="shallow-and-deep-neural-networks.html"><a href="shallow-and-deep-neural-networks.html#extending-logistic-regression"><i class="fa fa-check"></i><b>11.2.2</b> Extending Logistic Regression</a></li>
<li class="chapter" data-level="11.2.3" data-path="shallow-and-deep-neural-networks.html"><a href="shallow-and-deep-neural-networks.html#softmax-function"><i class="fa fa-check"></i><b>11.2.3</b> Softmax Function</a></li>
<li class="chapter" data-level="11.2.4" data-path="shallow-and-deep-neural-networks.html"><a href="shallow-and-deep-neural-networks.html#one-hot-encoding-and-decoding"><i class="fa fa-check"></i><b>11.2.4</b> One-Hot Encoding and Decoding</a></li>
<li class="chapter" data-level="11.2.5" data-path="shallow-and-deep-neural-networks.html"><a href="shallow-and-deep-neural-networks.html#cross-entropy-revisited"><i class="fa fa-check"></i><b>11.2.5</b> Cross-entropy Revisited</a></li>
<li class="chapter" data-level="11.2.6" data-path="shallow-and-deep-neural-networks.html"><a href="shallow-and-deep-neural-networks.html#problem-formulation-in-matrix-form"><i class="fa fa-check"></i><b>11.2.6</b> Problem Formulation in Matrix Form (**)</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="shallow-and-deep-neural-networks.html"><a href="shallow-and-deep-neural-networks.html#artificial-neural-networks"><i class="fa fa-check"></i><b>11.3</b> Artificial Neural Networks</a><ul>
<li class="chapter" data-level="11.3.1" data-path="shallow-and-deep-neural-networks.html"><a href="shallow-and-deep-neural-networks.html#artificial-neuron"><i class="fa fa-check"></i><b>11.3.1</b> Artificial Neuron</a></li>
<li class="chapter" data-level="11.3.2" data-path="shallow-and-deep-neural-networks.html"><a href="shallow-and-deep-neural-networks.html#logistic-regression-as-a-neural-network"><i class="fa fa-check"></i><b>11.3.2</b> Logistic Regression as a Neural Network</a></li>
<li class="chapter" data-level="11.3.3" data-path="shallow-and-deep-neural-networks.html"><a href="shallow-and-deep-neural-networks.html#example-in-r-6"><i class="fa fa-check"></i><b>11.3.3</b> Example in R</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="shallow-and-deep-neural-networks.html"><a href="shallow-and-deep-neural-networks.html#deep-neural-networks"><i class="fa fa-check"></i><b>11.4</b> Deep Neural Networks</a><ul>
<li class="chapter" data-level="11.4.1" data-path="shallow-and-deep-neural-networks.html"><a href="shallow-and-deep-neural-networks.html#introduction-14"><i class="fa fa-check"></i><b>11.4.1</b> Introduction</a></li>
<li class="chapter" data-level="11.4.2" data-path="shallow-and-deep-neural-networks.html"><a href="shallow-and-deep-neural-networks.html#activation-functions"><i class="fa fa-check"></i><b>11.4.2</b> Activation Functions</a></li>
<li class="chapter" data-level="11.4.3" data-path="shallow-and-deep-neural-networks.html"><a href="shallow-and-deep-neural-networks.html#example-in-r---2-layers"><i class="fa fa-check"></i><b>11.4.3</b> Example in R - 2 Layers</a></li>
<li class="chapter" data-level="11.4.4" data-path="shallow-and-deep-neural-networks.html"><a href="shallow-and-deep-neural-networks.html#example-in-r---6-layers"><i class="fa fa-check"></i><b>11.4.4</b> Example in R - 6 Layers</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="shallow-and-deep-neural-networks.html"><a href="shallow-and-deep-neural-networks.html#preprocessing-of-data"><i class="fa fa-check"></i><b>11.5</b> Preprocessing of Data</a><ul>
<li class="chapter" data-level="11.5.1" data-path="shallow-and-deep-neural-networks.html"><a href="shallow-and-deep-neural-networks.html#introduction-15"><i class="fa fa-check"></i><b>11.5.1</b> Introduction</a></li>
<li class="chapter" data-level="11.5.2" data-path="shallow-and-deep-neural-networks.html"><a href="shallow-and-deep-neural-networks.html#image-deskewing"><i class="fa fa-check"></i><b>11.5.2</b> Image Deskewing</a></li>
<li class="chapter" data-level="11.5.3" data-path="shallow-and-deep-neural-networks.html"><a href="shallow-and-deep-neural-networks.html#summary-of-all-the-models-considered"><i class="fa fa-check"></i><b>11.5.3</b> Summary of All the Models Considered</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="shallow-and-deep-neural-networks.html"><a href="shallow-and-deep-neural-networks.html#outro-9"><i class="fa fa-check"></i><b>11.6</b> Outro</a><ul>
<li class="chapter" data-level="11.6.1" data-path="shallow-and-deep-neural-networks.html"><a href="shallow-and-deep-neural-networks.html#remarks-9"><i class="fa fa-check"></i><b>11.6.1</b> Remarks</a></li>
<li class="chapter" data-level="11.6.2" data-path="shallow-and-deep-neural-networks.html"><a href="shallow-and-deep-neural-networks.html#beyond-mnist"><i class="fa fa-check"></i><b>11.6.2</b> Beyond MNIST</a></li>
<li class="chapter" data-level="11.6.3" data-path="shallow-and-deep-neural-networks.html"><a href="shallow-and-deep-neural-networks.html#further-reading-9"><i class="fa fa-check"></i><b>11.6.3</b> Further Reading</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="recommender-systems.html"><a href="recommender-systems.html"><i class="fa fa-check"></i><b>12</b> Recommender Systems</a><ul>
<li class="chapter" data-level="12.1" data-path="recommender-systems.html"><a href="recommender-systems.html#introduction-16"><i class="fa fa-check"></i><b>12.1</b> Introduction</a><ul>
<li class="chapter" data-level="12.1.1" data-path="recommender-systems.html"><a href="recommender-systems.html#the-netflix-prize"><i class="fa fa-check"></i><b>12.1.1</b> The Netflix Prize</a></li>
<li class="chapter" data-level="12.1.2" data-path="recommender-systems.html"><a href="recommender-systems.html#main-approaches"><i class="fa fa-check"></i><b>12.1.2</b> Main Approaches</a></li>
<li class="chapter" data-level="12.1.3" data-path="recommender-systems.html"><a href="recommender-systems.html#formalism-1"><i class="fa fa-check"></i><b>12.1.3</b> Formalism</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="recommender-systems.html"><a href="recommender-systems.html#collaborative-filtering"><i class="fa fa-check"></i><b>12.2</b> Collaborative Filtering</a><ul>
<li class="chapter" data-level="12.2.1" data-path="recommender-systems.html"><a href="recommender-systems.html#example"><i class="fa fa-check"></i><b>12.2.1</b> Example</a></li>
<li class="chapter" data-level="12.2.2" data-path="recommender-systems.html"><a href="recommender-systems.html#similarity-measures"><i class="fa fa-check"></i><b>12.2.2</b> Similarity Measures</a></li>
<li class="chapter" data-level="12.2.3" data-path="recommender-systems.html"><a href="recommender-systems.html#user-based-collaborative-filtering"><i class="fa fa-check"></i><b>12.2.3</b> User-Based Collaborative Filtering</a></li>
<li class="chapter" data-level="12.2.4" data-path="recommender-systems.html"><a href="recommender-systems.html#item-based-collaborative-filtering"><i class="fa fa-check"></i><b>12.2.4</b> Item-Based Collaborative Filtering</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="recommender-systems.html"><a href="recommender-systems.html#exercise-the-movielens-dataset"><i class="fa fa-check"></i><b>12.3</b> Exercise: The MovieLens Dataset (*)</a><ul>
<li class="chapter" data-level="12.3.1" data-path="recommender-systems.html"><a href="recommender-systems.html#dataset"><i class="fa fa-check"></i><b>12.3.1</b> Dataset</a></li>
<li class="chapter" data-level="12.3.2" data-path="recommender-systems.html"><a href="recommender-systems.html#data-cleansing"><i class="fa fa-check"></i><b>12.3.2</b> Data Cleansing</a></li>
<li class="chapter" data-level="12.3.3" data-path="recommender-systems.html"><a href="recommender-systems.html#item-item-similarities"><i class="fa fa-check"></i><b>12.3.3</b> Item-Item Similarities</a></li>
<li class="chapter" data-level="12.3.4" data-path="recommender-systems.html"><a href="recommender-systems.html#example-recommendations"><i class="fa fa-check"></i><b>12.3.4</b> Example Recommendations</a></li>
<li class="chapter" data-level="12.3.5" data-path="recommender-systems.html"><a href="recommender-systems.html#clustering"><i class="fa fa-check"></i><b>12.3.5</b> Clustering</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="recommender-systems.html"><a href="recommender-systems.html#outro-10"><i class="fa fa-check"></i><b>12.4</b> Outro</a><ul>
<li class="chapter" data-level="12.4.1" data-path="recommender-systems.html"><a href="recommender-systems.html#remarks-10"><i class="fa fa-check"></i><b>12.4.1</b> Remarks</a></li>
<li class="chapter" data-level="12.4.2" data-path="recommender-systems.html"><a href="recommender-systems.html#further-reading-10"><i class="fa fa-check"></i><b>12.4.2</b> Further Reading</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="natural-language-processing.html"><a href="natural-language-processing.html"><i class="fa fa-check"></i><b>13</b> Natural Language Processing</a><ul>
<li class="chapter" data-level="13.1" data-path="natural-language-processing.html"><a href="natural-language-processing.html#to-do"><i class="fa fa-check"></i><b>13.1</b> TO DO</a></li>
<li class="chapter" data-level="13.2" data-path="natural-language-processing.html"><a href="natural-language-processing.html#further-reading-11"><i class="fa fa-check"></i><b>13.2</b> Further Reading</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="notation-convention.html"><a href="notation-convention.html"><i class="fa fa-check"></i><b>A</b> Notation Convention</a></li>
<li class="chapter" data-level="B" data-path="setting-up-the-r-environment.html"><a href="setting-up-the-r-environment.html"><i class="fa fa-check"></i><b>B</b> Setting Up the R Environment</a><ul>
<li class="chapter" data-level="B.1" data-path="setting-up-the-r-environment.html"><a href="setting-up-the-r-environment.html#installing-r"><i class="fa fa-check"></i><b>B.1</b> Installing R</a></li>
<li class="chapter" data-level="B.2" data-path="setting-up-the-r-environment.html"><a href="setting-up-the-r-environment.html#installing-an-ide"><i class="fa fa-check"></i><b>B.2</b> Installing an IDE</a></li>
<li class="chapter" data-level="B.3" data-path="setting-up-the-r-environment.html"><a href="setting-up-the-r-environment.html#installing-recommended-packages"><i class="fa fa-check"></i><b>B.3</b> Installing Recommended Packages</a></li>
<li class="chapter" data-level="B.4" data-path="setting-up-the-r-environment.html"><a href="setting-up-the-r-environment.html#first-r-script-in-rstudio"><i class="fa fa-check"></i><b>B.4</b> First R Script in RStudio</a></li>
<li class="chapter" data-level="B.5" data-path="setting-up-the-r-environment.html"><a href="setting-up-the-r-environment.html#exercises-7"><i class="fa fa-check"></i><b>B.5</b> Exercises</a><ul>
<li class="chapter" data-level="B.5.1" data-path="setting-up-the-r-environment.html"><a href="setting-up-the-r-environment.html#first-steps-with-vectors"><i class="fa fa-check"></i><b>B.5.1</b> First Steps with Vectors</a></li>
<li class="chapter" data-level="B.5.2" data-path="setting-up-the-r-environment.html"><a href="setting-up-the-r-environment.html#basic-plotting"><i class="fa fa-check"></i><b>B.5.2</b> Basic Plotting</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="C" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html"><i class="fa fa-check"></i><b>C</b> Vector Algebra in R</a><ul>
<li class="chapter" data-level="C.1" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#motivation-1"><i class="fa fa-check"></i><b>C.1</b> Motivation</a></li>
<li class="chapter" data-level="C.2" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#numeric-vectors"><i class="fa fa-check"></i><b>C.2</b> Numeric Vectors</a><ul>
<li class="chapter" data-level="C.2.1" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#creating-numeric-vectors"><i class="fa fa-check"></i><b>C.2.1</b> Creating Numeric Vectors</a></li>
<li class="chapter" data-level="C.2.2" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#vector-scalar-operations"><i class="fa fa-check"></i><b>C.2.2</b> Vector-Scalar Operations</a></li>
<li class="chapter" data-level="C.2.3" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#vector-vector-operations"><i class="fa fa-check"></i><b>C.2.3</b> Vector-Vector Operations</a></li>
<li class="chapter" data-level="C.2.4" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#aggregation-functions"><i class="fa fa-check"></i><b>C.2.4</b> Aggregation Functions</a></li>
<li class="chapter" data-level="C.2.5" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#special-functions"><i class="fa fa-check"></i><b>C.2.5</b> Special Functions</a></li>
<li class="chapter" data-level="C.2.6" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#norms-and-distances"><i class="fa fa-check"></i><b>C.2.6</b> Norms and Distances</a></li>
<li class="chapter" data-level="C.2.7" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#dot-product"><i class="fa fa-check"></i><b>C.2.7</b> Dot Product (*)</a></li>
<li class="chapter" data-level="C.2.8" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#missing-and-other-special-values"><i class="fa fa-check"></i><b>C.2.8</b> Missing and Other Special Values</a></li>
</ul></li>
<li class="chapter" data-level="C.3" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#logical-vectors"><i class="fa fa-check"></i><b>C.3</b> Logical Vectors</a><ul>
<li class="chapter" data-level="C.3.1" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#creating-logical-vectors"><i class="fa fa-check"></i><b>C.3.1</b> Creating Logical Vectors</a></li>
<li class="chapter" data-level="C.3.2" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#logical-operations"><i class="fa fa-check"></i><b>C.3.2</b> Logical Operations</a></li>
<li class="chapter" data-level="C.3.3" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#comparison-operations"><i class="fa fa-check"></i><b>C.3.3</b> Comparison Operations</a></li>
<li class="chapter" data-level="C.3.4" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#aggregation-functions-1"><i class="fa fa-check"></i><b>C.3.4</b> Aggregation Functions</a></li>
</ul></li>
<li class="chapter" data-level="C.4" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#character-vectors"><i class="fa fa-check"></i><b>C.4</b> Character Vectors</a><ul>
<li class="chapter" data-level="C.4.1" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#creating-character-vectors"><i class="fa fa-check"></i><b>C.4.1</b> Creating Character Vectors</a></li>
<li class="chapter" data-level="C.4.2" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#concatenating-character-vectors"><i class="fa fa-check"></i><b>C.4.2</b> Concatenating Character Vectors</a></li>
<li class="chapter" data-level="C.4.3" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#collapsing-character-vectors"><i class="fa fa-check"></i><b>C.4.3</b> Collapsing Character Vectors</a></li>
</ul></li>
<li class="chapter" data-level="C.5" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#vector-subsetting"><i class="fa fa-check"></i><b>C.5</b> Vector Subsetting</a><ul>
<li class="chapter" data-level="C.5.1" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#subsetting-with-positive-indices"><i class="fa fa-check"></i><b>C.5.1</b> Subsetting with Positive Indices</a></li>
<li class="chapter" data-level="C.5.2" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#subsetting-with-negative-indices"><i class="fa fa-check"></i><b>C.5.2</b> Subsetting with Negative Indices</a></li>
<li class="chapter" data-level="C.5.3" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#subsetting-with-logical-vectors"><i class="fa fa-check"></i><b>C.5.3</b> Subsetting with Logical Vectors</a></li>
<li class="chapter" data-level="C.5.4" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#replacing-elements"><i class="fa fa-check"></i><b>C.5.4</b> Replacing Elements</a></li>
<li class="chapter" data-level="C.5.5" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#other-functions"><i class="fa fa-check"></i><b>C.5.5</b> Other Functions</a></li>
</ul></li>
<li class="chapter" data-level="C.6" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#named-vectors"><i class="fa fa-check"></i><b>C.6</b> Named Vectors</a><ul>
<li class="chapter" data-level="C.6.1" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#creating-named-vectors"><i class="fa fa-check"></i><b>C.6.1</b> Creating Named Vectors</a></li>
<li class="chapter" data-level="C.6.2" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#subsetting-named-vectors-with-character-string-indices"><i class="fa fa-check"></i><b>C.6.2</b> Subsetting Named Vectors with Character String Indices</a></li>
</ul></li>
<li class="chapter" data-level="C.7" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#factors"><i class="fa fa-check"></i><b>C.7</b> Factors</a><ul>
<li class="chapter" data-level="C.7.1" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#creating-factors"><i class="fa fa-check"></i><b>C.7.1</b> Creating Factors</a></li>
<li class="chapter" data-level="C.7.2" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#levels"><i class="fa fa-check"></i><b>C.7.2</b> Levels</a></li>
<li class="chapter" data-level="C.7.3" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#internal-representation"><i class="fa fa-check"></i><b>C.7.3</b> Internal Representation (*)</a></li>
</ul></li>
<li class="chapter" data-level="C.8" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#lists"><i class="fa fa-check"></i><b>C.8</b> Lists</a><ul>
<li class="chapter" data-level="C.8.1" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#creating-lists"><i class="fa fa-check"></i><b>C.8.1</b> Creating Lists</a></li>
<li class="chapter" data-level="C.8.2" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#named-lists"><i class="fa fa-check"></i><b>C.8.2</b> Named Lists</a></li>
<li class="chapter" data-level="C.8.3" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#subsetting-and-extracting-from-lists"><i class="fa fa-check"></i><b>C.8.3</b> Subsetting and Extracting From Lists</a></li>
<li class="chapter" data-level="C.8.4" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#common-operations"><i class="fa fa-check"></i><b>C.8.4</b> Common Operations</a></li>
</ul></li>
<li class="chapter" data-level="C.9" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#exercises-8"><i class="fa fa-check"></i><b>C.9</b> Exercises</a><ul>
<li class="chapter" data-level="C.9.1" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#audeur-exchange-rates"><i class="fa fa-check"></i><b>C.9.1</b> AUD/EUR Exchange Rates</a></li>
</ul></li>
<li class="chapter" data-level="C.10" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html#further-reading-12"><i class="fa fa-check"></i><b>C.10</b> Further Reading</a></li>
</ul></li>
<li class="chapter" data-level="D" data-path="matrix-algebra-in-r.html"><a href="matrix-algebra-in-r.html"><i class="fa fa-check"></i><b>D</b> Matrix Algebra in R</a><ul>
<li class="chapter" data-level="D.1" data-path="matrix-algebra-in-r.html"><a href="matrix-algebra-in-r.html#creating-matrices"><i class="fa fa-check"></i><b>D.1</b> Creating Matrices</a><ul>
<li class="chapter" data-level="D.1.1" data-path="matrix-algebra-in-r.html"><a href="matrix-algebra-in-r.html#matrix"><i class="fa fa-check"></i><b>D.1.1</b> <code>matrix()</code></a></li>
<li class="chapter" data-level="D.1.2" data-path="matrix-algebra-in-r.html"><a href="matrix-algebra-in-r.html#stacking-vectors"><i class="fa fa-check"></i><b>D.1.2</b> Stacking Vectors</a></li>
<li class="chapter" data-level="D.1.3" data-path="matrix-algebra-in-r.html"><a href="matrix-algebra-in-r.html#beyond-numeric-matrices"><i class="fa fa-check"></i><b>D.1.3</b> Beyond Numeric Matrices</a></li>
<li class="chapter" data-level="D.1.4" data-path="matrix-algebra-in-r.html"><a href="matrix-algebra-in-r.html#naming-rows-and-columns"><i class="fa fa-check"></i><b>D.1.4</b> Naming Rows and Columns</a></li>
<li class="chapter" data-level="D.1.5" data-path="matrix-algebra-in-r.html"><a href="matrix-algebra-in-r.html#other-methods"><i class="fa fa-check"></i><b>D.1.5</b> Other Methods</a></li>
<li class="chapter" data-level="D.1.6" data-path="matrix-algebra-in-r.html"><a href="matrix-algebra-in-r.html#internal-representation-1"><i class="fa fa-check"></i><b>D.1.6</b> Internal Representation (*)</a></li>
</ul></li>
<li class="chapter" data-level="D.2" data-path="matrix-algebra-in-r.html"><a href="matrix-algebra-in-r.html#common-operations-1"><i class="fa fa-check"></i><b>D.2</b> Common Operations</a><ul>
<li class="chapter" data-level="D.2.1" data-path="matrix-algebra-in-r.html"><a href="matrix-algebra-in-r.html#matrix-transpose"><i class="fa fa-check"></i><b>D.2.1</b> Matrix Transpose</a></li>
<li class="chapter" data-level="D.2.2" data-path="matrix-algebra-in-r.html"><a href="matrix-algebra-in-r.html#matrix-scalar-operations"><i class="fa fa-check"></i><b>D.2.2</b> Matrix-Scalar Operations</a></li>
<li class="chapter" data-level="D.2.3" data-path="matrix-algebra-in-r.html"><a href="matrix-algebra-in-r.html#matrix-matrix-operations"><i class="fa fa-check"></i><b>D.2.3</b> Matrix-Matrix Operations</a></li>
<li class="chapter" data-level="D.2.4" data-path="matrix-algebra-in-r.html"><a href="matrix-algebra-in-r.html#matrix-multiplication"><i class="fa fa-check"></i><b>D.2.4</b> Matrix Multiplication (*)</a></li>
<li class="chapter" data-level="D.2.5" data-path="matrix-algebra-in-r.html"><a href="matrix-algebra-in-r.html#aggregation-of-rows-and-columns"><i class="fa fa-check"></i><b>D.2.5</b> Aggregation of Rows and Columns</a></li>
<li class="chapter" data-level="D.2.6" data-path="matrix-algebra-in-r.html"><a href="matrix-algebra-in-r.html#vectorised-special-functions"><i class="fa fa-check"></i><b>D.2.6</b> Vectorised Special Functions</a></li>
<li class="chapter" data-level="D.2.7" data-path="matrix-algebra-in-r.html"><a href="matrix-algebra-in-r.html#matrix-vector-operations"><i class="fa fa-check"></i><b>D.2.7</b> Matrix-Vector Operations</a></li>
</ul></li>
<li class="chapter" data-level="D.3" data-path="matrix-algebra-in-r.html"><a href="matrix-algebra-in-r.html#matrix-subsetting"><i class="fa fa-check"></i><b>D.3</b> Matrix Subsetting</a><ul>
<li class="chapter" data-level="D.3.1" data-path="matrix-algebra-in-r.html"><a href="matrix-algebra-in-r.html#selecting-individual-elements"><i class="fa fa-check"></i><b>D.3.1</b> Selecting Individual Elements</a></li>
<li class="chapter" data-level="D.3.2" data-path="matrix-algebra-in-r.html"><a href="matrix-algebra-in-r.html#selecting-rows-and-columns"><i class="fa fa-check"></i><b>D.3.2</b> Selecting Rows and Columns</a></li>
<li class="chapter" data-level="D.3.3" data-path="matrix-algebra-in-r.html"><a href="matrix-algebra-in-r.html#selecting-submatrices"><i class="fa fa-check"></i><b>D.3.3</b> Selecting Submatrices</a></li>
<li class="chapter" data-level="D.3.4" data-path="matrix-algebra-in-r.html"><a href="matrix-algebra-in-r.html#selecting-based-on-logical-vectors-and-matrices"><i class="fa fa-check"></i><b>D.3.4</b> Selecting Based on Logical Vectors and Matrices</a></li>
<li class="chapter" data-level="D.3.5" data-path="matrix-algebra-in-r.html"><a href="matrix-algebra-in-r.html#selecting-based-on-two-column-matrices"><i class="fa fa-check"></i><b>D.3.5</b> Selecting Based on Two-Column Matrices</a></li>
</ul></li>
<li class="chapter" data-level="D.4" data-path="matrix-algebra-in-r.html"><a href="matrix-algebra-in-r.html#exercises-9"><i class="fa fa-check"></i><b>D.4</b> Exercises</a><ul>
<li class="chapter" data-level="D.4.1" data-path="matrix-algebra-in-r.html"><a href="matrix-algebra-in-r.html#currency-exchange-rates"><i class="fa fa-check"></i><b>D.4.1</b> Currency Exchange Rates</a></li>
<li class="chapter" data-level="D.4.2" data-path="matrix-algebra-in-r.html"><a href="matrix-algebra-in-r.html#currency-exchange-rates-relative-to-1999"><i class="fa fa-check"></i><b>D.4.2</b> Currency Exchange Rates Relative to 1999</a></li>
</ul></li>
<li class="chapter" data-level="D.5" data-path="matrix-algebra-in-r.html"><a href="matrix-algebra-in-r.html#further-reading-13"><i class="fa fa-check"></i><b>D.5</b> Further Reading</a></li>
</ul></li>
<li class="chapter" data-level="E" data-path="data-frame-wrangling-in-r.html"><a href="data-frame-wrangling-in-r.html"><i class="fa fa-check"></i><b>E</b> Data Frame Wrangling in R</a><ul>
<li class="chapter" data-level="E.1" data-path="data-frame-wrangling-in-r.html"><a href="data-frame-wrangling-in-r.html#creating-data-frames"><i class="fa fa-check"></i><b>E.1</b> Creating Data Frames</a></li>
<li class="chapter" data-level="E.2" data-path="data-frame-wrangling-in-r.html"><a href="data-frame-wrangling-in-r.html#importing-data-frames"><i class="fa fa-check"></i><b>E.2</b> Importing Data Frames</a></li>
<li class="chapter" data-level="E.3" data-path="data-frame-wrangling-in-r.html"><a href="data-frame-wrangling-in-r.html#data-frame-subsetting"><i class="fa fa-check"></i><b>E.3</b> Data Frame Subsetting</a><ul>
<li class="chapter" data-level="E.3.1" data-path="data-frame-wrangling-in-r.html"><a href="data-frame-wrangling-in-r.html#each-data-frame-is-a-list"><i class="fa fa-check"></i><b>E.3.1</b> Each Data Frame is a List</a></li>
<li class="chapter" data-level="E.3.2" data-path="data-frame-wrangling-in-r.html"><a href="data-frame-wrangling-in-r.html#each-data-frame-is-matrix-like"><i class="fa fa-check"></i><b>E.3.2</b> Each Data Frame is Matrix-like</a></li>
</ul></li>
<li class="chapter" data-level="E.4" data-path="data-frame-wrangling-in-r.html"><a href="data-frame-wrangling-in-r.html#common-operations-2"><i class="fa fa-check"></i><b>E.4</b> Common Operations</a></li>
<li class="chapter" data-level="E.5" data-path="data-frame-wrangling-in-r.html"><a href="data-frame-wrangling-in-r.html#metaprogramming-and-formulas"><i class="fa fa-check"></i><b>E.5</b> Metaprogramming and Formulas (*)</a></li>
<li class="chapter" data-level="E.6" data-path="data-frame-wrangling-in-r.html"><a href="data-frame-wrangling-in-r.html#exercises-10"><i class="fa fa-check"></i><b>E.6</b> Exercises</a><ul>
<li class="chapter" data-level="E.6.1" data-path="data-frame-wrangling-in-r.html"><a href="data-frame-wrangling-in-r.html#urban-forest"><i class="fa fa-check"></i><b>E.6.1</b> Urban Forest</a></li>
</ul></li>
<li class="chapter" data-level="E.7" data-path="data-frame-wrangling-in-r.html"><a href="data-frame-wrangling-in-r.html#air-quality"><i class="fa fa-check"></i><b>E.7</b> Air Quality</a></li>
<li class="chapter" data-level="E.8" data-path="data-frame-wrangling-in-r.html"><a href="data-frame-wrangling-in-r.html#further-reading-14"><i class="fa fa-check"></i><b>E.8</b> Further Reading</a></li>
</ul></li>
<li class="chapter" data-level="F" data-path="datasets.html"><a href="datasets.html"><i class="fa fa-check"></i><b>F</b> Datasets</a><ul>
<li class="chapter" data-level="F.1" data-path="datasets.html"><a href="datasets.html#sustainable-society-indices"><i class="fa fa-check"></i><b>F.1</b> Sustainable Society Indices</a></li>
<li class="chapter" data-level="F.2" data-path="datasets.html"><a href="datasets.html#air-quality-1"><i class="fa fa-check"></i><b>F.2</b> Air Quality</a></li>
<li class="chapter" data-level="F.3" data-path="datasets.html"><a href="datasets.html#currency-exchange-rates-1"><i class="fa fa-check"></i><b>F.3</b> Currency Exchange Rates</a></li>
<li class="chapter" data-level="F.4" data-path="datasets.html"><a href="datasets.html#urban-forest-1"><i class="fa fa-check"></i><b>F.4</b> Urban Forest</a></li>
<li class="chapter" data-level="F.5" data-path="datasets.html"><a href="datasets.html#wine-quality"><i class="fa fa-check"></i><b>F.5</b> Wine Quality</a></li>
<li class="chapter" data-level="F.6" data-path="datasets.html"><a href="datasets.html#the-world-factbook-countries-of-the-world"><i class="fa fa-check"></i><b>F.6</b> The World Factbook (Countries of the World)</a></li>
<li class="chapter" data-level="F.7" data-path="datasets.html"><a href="datasets.html#edstats-country-level-education-statistics"><i class="fa fa-check"></i><b>F.7</b> EdStats (Country-Level Education Statistics)</a></li>
<li class="chapter" data-level="F.8" data-path="datasets.html"><a href="datasets.html#food-and-nutrient-database-for-dietary-studies-fndds"><i class="fa fa-check"></i><b>F.8</b> Food and Nutrient Database for Dietary Studies (FNDDS)</a></li>
<li class="chapter" data-level="F.9" data-path="datasets.html"><a href="datasets.html#clustering-benchmarks"><i class="fa fa-check"></i><b>F.9</b> Clustering Benchmarks</a></li>
<li class="chapter" data-level="F.10" data-path="datasets.html"><a href="datasets.html#movie-lens-todo"><i class="fa fa-check"></i><b>F.10</b> Movie Lens (TODO)</a></li>
<li class="chapter" data-level="F.11" data-path="datasets.html"><a href="datasets.html#other-todo"><i class="fa fa-check"></i><b>F.11</b> Other (TODO)</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li style='font-size: smaller' ><a href="https://creativecommons.org/licenses/by-nc-nd/4.0/">Licensed under CC BY-NC-ND 4.0</a></li>
<li style='font-size: smaller' ><a href="./">DRAFT v0.3 2020-06-12 22:49 (9a1ce97)</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Lightweight Machine Learning Classics with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="agglomerative-hierarchical-clustering" class="section level1">
<h1><span class="header-section-number">2</span> Agglomerative Hierarchical Clustering</h1>
<!-- (C) 2020 Marek Gagolewski, https://www.gagolewski.com -->
<div id="agglomerative-hierarchical-clustering-1" class="section level2">
<h2><span class="header-section-number">2.1</span> Agglomerative Hierarchical Clustering</h2>
<p>Formally, given <span class="math inline">\(K\ge 2\)</span>, <strong>clustering</strong> aims is to find a <em>special kind</em>
of a <strong><span class="math inline">\(K\)</span>-partition</strong> of the input data set <span class="math inline">\(\mathbf{X}\)</span>.</p>
<dl>
<dt>Definition.</dt>
<dd><p>We say that <span class="math inline">\(\mathcal{C}=\{C_1,\dots,C_K\}\)</span> is a <strong><span class="math inline">\(K\)</span>-partition</strong>
of <span class="math inline">\(\mathbf{X}\)</span> of size <span class="math inline">\(n\)</span>,
whenever:</p>
<ul>
<li><span class="math inline">\(C_k\neq\emptyset\)</span> for all <span class="math inline">\(k\)</span> (each set is nonempty),</li>
<li><span class="math inline">\(C_k\cap C_l=\emptyset\)</span> for all <span class="math inline">\(k\neq l\)</span> (sets are pairwise disjoint),</li>
<li><span class="math inline">\(\bigcup_{k=1}^K C_k=\mathbf{X}\)</span> (no point is neglected).</li>
</ul>
</dd>
</dl>
<p>This can also be thought of as assigning each point a unique label <span class="math inline">\(\{1,\dots,K\}\)</span>
(think: colouring of the points, where each number has a colour).
We will consider the point <span class="math inline">\(\mathbf{x}_{i,\cdot}\)</span> as labelled <span class="math inline">\(j\)</span>
if and only if it belongs to cluster <span class="math inline">\(C_j\)</span>, i.e., <span class="math inline">\(\mathbf{x}_{i,\cdot}\in C_j\)</span>.</p>
<p>Example applications of clustering:</p>
<ul>
<li><em>taxonomisation</em>: e.g.,
partition the consumers to more “uniform”
groups to better understand who they are and what do they need,</li>
<li><em>image processing</em>:
e.g., object detection, like tumour tissues on medical images,</li>
<li><em>complex networks analysis</em>:
e.g., detecting communities in friendship,
retweets and other networks,</li>
<li><em>fine-tuning supervised learning algorithms</em>:
e.g., recommender systems indicating content
that was rated highly by users from the same group
or learning multiple manifolds in a dimension reduction task.</li>
</ul>
<p>The number of possible <span class="math inline">\(K\)</span>-partitions of a set with <span class="math inline">\(n\)</span> elements is given by
<em>the Stirling number of the second kind</em>:</p>
<p><span class="math display">\[
\left\{{n \atop K}\right\}={\frac  {1}{K!}}\sum _{{j=0}}^{{K}}(-1)^{{K-j}}{\binom  {K}{j}}j^{n};
\]</span></p>
<p>e.g., already <span class="math inline">\(\left\{{n \atop 2}\right\}=2^{n-1}-1\)</span>
and <span class="math inline">\(\left\{{n \atop 3}\right\}=O(3^n)\)</span> – that is a lot.
Certainly, we are not just interested in “any” partition – some of them
will be more meaningful or valuable than others.
However, even one of the most famous ML textbooks provides us with only
a vague hint of what we might be looking for:</p>
<dl>
<dt>“Definition”.</dt>
<dd><p>Clustering concerns “segmenting a collection of objects into subsets
so that those within each cluster are more <strong>closely related</strong>
to one another than objects assigned to different clusters” <span class="citation">(Hastie et al. <a href="references.html#ref-esl">2017</a>)</span>.</p>
</dd>
</dl>
<p>It is not uncommon <!-- TODO: cite -->
to equate the general definition of data clustering problems with… the
particular outputs yield by specific clustering algorithms. It some sense,
that sounds fair. From this perspective, we might be interested in
identifying the two main types of clustering algorithms:</p>
<ul>
<li><strong>parametric</strong> (model-based):
<ul>
<li>find clusters of specific shapes or following specific multidimensional
probability distributions,</li>
<li>e.g., <span class="math inline">\(K\)</span>-means, expectation-maximisation for Gaussian mixtures (EM),
average linkage agglomerative clustering;</li>
</ul></li>
<li><strong>nonparametric</strong> (model-free):
<ul>
<li>identify high-density or well-separable regions,
perhaps in the presence of noise points,</li>
<li>e.g., single linkage agglomerative clustering, Genie, (H)DBSCAN, BIRCH.</li>
</ul></li>
</ul>
<p>In this chapter we’ll take a look at two classical approaches to clustering:</p>
<ul>
<li><em>K-means clustering</em> that looks for a specific number of clusters,</li>
<li><em>(agglomerative) hierarchical clustering</em> that outputs a whole hierarchy
of nested data partitions.</li>
</ul>
<div id="introduction-1" class="section level3">
<h3><span class="header-section-number">2.1.1</span> Introduction</h3>
<p>In K-means, we need to specify the number of clusters, <span class="math inline">\(K\)</span>, in advance.
What if we don’t have any idea how to choose this parameter (which is often
the case)?</p>
<p>Also, the problem with K-means is that there is no guarantee that a
<span class="math inline">\(K\)</span>-partition is any “similar” to the <span class="math inline">\(K&#39;\)</span>-one for <span class="math inline">\(K\neq K&#39;\)</span>,
see Figure <a href="agglomerative-hierarchical-clustering.html#fig:kmeans_different_K">1</a>.</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb32-1" title="1">X &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(iris[,<span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">2</span>)])</a>
<a class="sourceLine" id="cb32-2" title="2"><span class="co"># never forget to set nstart&gt;&gt;1!</span></a>
<a class="sourceLine" id="cb32-3" title="3">km &lt;-<span class="st"> </span><span class="kw">kmeans</span>(X, <span class="dt">centers=</span><span class="dv">3</span>, <span class="dt">nstart=</span><span class="dv">10</span>)</a>
<a class="sourceLine" id="cb32-4" title="4">km<span class="op">$</span>cluster <span class="co"># labels assigned to each of 150 points:</span></a></code></pre></div>
<pre><code>##   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
##  [34] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
##  [67] 3 3 3 3 3 3 3 3 3 3 3 2 3 3 3 3 3 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
## [100] 3 2 2 2 2 2 2 3 2 2 2 2 2 2 3 2 2 2 2 2 3 2 3 2 3 2 2 3 3 2 2 2 2
## [133] 2 2 2 2 2 2 3 2 2 2 2 2 2 2 3 2 2 2</code></pre>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb34-1" title="1">km1 &lt;-<span class="st"> </span><span class="kw">kmeans</span>(X, <span class="dv">3</span>, <span class="dt">nstart=</span><span class="dv">10</span>)</a>
<a class="sourceLine" id="cb34-2" title="2">km2 &lt;-<span class="st"> </span><span class="kw">kmeans</span>(X, <span class="dv">4</span>, <span class="dt">nstart=</span><span class="dv">10</span>)</a>
<a class="sourceLine" id="cb34-3" title="3"><span class="kw">plot</span>(X, <span class="dt">col=</span>km1<span class="op">$</span>cluster, <span class="dt">pch=</span>km2<span class="op">$</span>cluster, <span class="dt">asp=</span><span class="dv">1</span>)</a></code></pre></div>
<div class="figure">
<img src="02-hclust-figures/kmeans_different_K-1.svg" alt="Figure 1: 3-means (colours) vs. 4-means (symbols) on example data; the “circle” cluster cannot decide if it likes the green or the black one more" id="fig:kmeans_different_K" />
<p class="caption">Figure 1: 3-means (colours) vs. 4-means (symbols) on example data; the “circle” cluster cannot decide if it likes the green or the black one more</p>
</div>
<p>Hierarchical methods, on the other hand, output a whole hierarchy
of mutually <em>nested</em> partitions, which increase the interpretability
of the results.
A <span class="math inline">\(K\)</span>-partition for any <span class="math inline">\(K\)</span> can be extracted later at any time.</p>
<p>In this book we will be interested in <em>agglomerative</em> hierarchical algorithms:</p>
<ul>
<li><p>at the lowest level of the hierarchy, each point belongs to its own
cluster (there are <span class="math inline">\(n\)</span> singletons);</p></li>
<li><p>at the highest level of the hierarchy,
there is one cluster that embraces all the points;</p></li>
<li><p>moving from the <span class="math inline">\(i\)</span>-th to the <span class="math inline">\((i+1)\)</span>-th level,
we select (somehow; see below) a pair of clusters to be merged.</p></li>
</ul>
</div>
<div id="example-in-r" class="section level3">
<h3><span class="header-section-number">2.1.2</span> Example in R</h3>
<p>The most basic implementation of a few
agglomerative hierarchical clustering algorithms
is provided by the <code>hclust()</code> function, which works on a pairwise
distance matrix.</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb35-1" title="1"><span class="co"># Euclidean distances between all pairs of points:</span></a>
<a class="sourceLine" id="cb35-2" title="2">D &lt;-<span class="st"> </span><span class="kw">dist</span>(X)</a>
<a class="sourceLine" id="cb35-3" title="3"><span class="co"># Apply Complete Linkage (the default, details below):</span></a>
<a class="sourceLine" id="cb35-4" title="4">h &lt;-<span class="st"> </span><span class="kw">hclust</span>(D) <span class="co"># method=&quot;complete&quot;</span></a>
<a class="sourceLine" id="cb35-5" title="5"><span class="kw">print</span>(h)</a></code></pre></div>
<pre><code>## 
## Call:
## hclust(d = D)
## 
## Cluster method   : complete 
## Distance         : euclidean 
## Number of objects: 150</code></pre>
<dl>
<dt>Remark.</dt>
<dd><p>There are <span class="math inline">\(n(n-1)/2\)</span> unique pairwise distances between <span class="math inline">\(n\)</span> points.
Don’t try calling <code>dist()</code> on large data matrices.
Already <span class="math inline">\(n=100{,}000\)</span> points consumes 40 GB of available memory
(assuming that each distance is stored as an 8-byte double-precision floating
point number); packages <code>fastcluster</code> and <code>genie</code>, among other,
aim to solve this problem.</p>
</dd>
</dl>
<!--
#n <- 100000
#8*n*(n-1)/2/1e9
-->
<p>The obtained hierarchy (<em>tree</em>) can be <em>cut</em> at an arbitrary level
by applying the <code>cutree()</code> function.</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb37-1" title="1"><span class="kw">cutree</span>(h, <span class="dt">k=</span><span class="dv">3</span>) <span class="co"># extract the 3-partition</span></a></code></pre></div>
<pre><code>##   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
##  [34] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
##  [67] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
## [100] 2 3 2 3 3 3 3 2 3 3 3 2 3 3 2 2 2 3 3 3 2 3 2 3 2 3 3 2 2 3 3 3 3
## [133] 3 2 3 3 3 3 2 3 3 2 2 3 3 2 2 2 3 2</code></pre>
<p>The cuts of the hierarchy at different levels
are depicted in Figure <a href="agglomerative-hierarchical-clustering.html#fig:complete_linkage_hier5_intro">2</a>.
The obtained 3-partition also matches the true Iris species quite well.
However, now it makes total sense to “zoom” our partitioning in or out
and investigate how are the subgroups decomposed or aggregated when we change
<span class="math inline">\(K\)</span>.</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb39-1" title="1"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</a>
<a class="sourceLine" id="cb39-2" title="2"><span class="kw">plot</span>(X, <span class="dt">col=</span><span class="kw">cutree</span>(h, <span class="dt">k=</span><span class="dv">5</span>), <span class="dt">ann=</span><span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb39-3" title="3"><span class="kw">legend</span>(<span class="st">&quot;top&quot;</span>, <span class="dt">legend=</span><span class="st">&quot;k=5&quot;</span>, <span class="dt">bg=</span><span class="st">&quot;white&quot;</span>)</a>
<a class="sourceLine" id="cb39-4" title="4"><span class="kw">plot</span>(X, <span class="dt">col=</span><span class="kw">cutree</span>(h, <span class="dt">k=</span><span class="dv">4</span>), <span class="dt">ann=</span><span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb39-5" title="5"><span class="kw">legend</span>(<span class="st">&quot;top&quot;</span>, <span class="dt">legend=</span><span class="st">&quot;k=4&quot;</span>, <span class="dt">bg=</span><span class="st">&quot;white&quot;</span>)</a>
<a class="sourceLine" id="cb39-6" title="6"><span class="kw">plot</span>(X, <span class="dt">col=</span><span class="kw">cutree</span>(h, <span class="dt">k=</span><span class="dv">3</span>), <span class="dt">ann=</span><span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb39-7" title="7"><span class="kw">legend</span>(<span class="st">&quot;top&quot;</span>, <span class="dt">legend=</span><span class="st">&quot;k=3&quot;</span>, <span class="dt">bg=</span><span class="st">&quot;white&quot;</span>)</a>
<a class="sourceLine" id="cb39-8" title="8"><span class="kw">plot</span>(X, <span class="dt">col=</span><span class="kw">cutree</span>(h, <span class="dt">k=</span><span class="dv">2</span>), <span class="dt">ann=</span><span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb39-9" title="9"><span class="kw">legend</span>(<span class="st">&quot;top&quot;</span>, <span class="dt">legend=</span><span class="st">&quot;k=2&quot;</span>, <span class="dt">bg=</span><span class="st">&quot;white&quot;</span>)</a></code></pre></div>
<div class="figure">
<img src="02-hclust-figures/complete_linkage_hier5_intro-1.svg" alt="Figure 2: Complete linkage – 4 different cuts" id="fig:complete_linkage_hier5_intro" />
<p class="caption">Figure 2: Complete linkage – 4 different cuts</p>
</div>
</div>
<div id="linkage-functions" class="section level3">
<h3><span class="header-section-number">2.1.3</span> Linkage Functions</h3>
<p>Let’s formalise the clustering process.
Initially, <span class="math inline">\(\mathcal{C}^{(0)}=\{\{\mathbf{x}_{1,\cdot}\},\dots,\{\mathbf{x}_{n,\cdot}\}\}\)</span>,
i.e., each point is a member of its own cluster.</p>
<p>While an agglomerative hierarchical clustering algorithm is being computed,
there are <span class="math inline">\(n-k\)</span> clusters at the <span class="math inline">\(k\)</span>-th step of the procedure,
<span class="math inline">\(\mathcal{C}^{(k)}=\{C_1^{(k)},\dots,C_{n-k}^{(k)}\}\)</span>.</p>
<p>When proceeding from step <span class="math inline">\(k\)</span> to <span class="math inline">\(k+1\)</span>,
we determine the two groups <span class="math inline">\(C_u^{(k)}\)</span> and <span class="math inline">\(C_v^{(k)}\)</span>, <span class="math inline">\(u&lt;v\)</span>,
to be <em>merged</em> together so that the clustering at the higher level
is of the form:
<span class="math display">\[
\mathcal{C}^{(k+1)} = \left\{
C_1^{(k)},\dots,C_{u-1}^{(k)},
C_u^{(k)}{\cup C_v^{(k)}},
C_{u+1}^{(k)},\dots,C_{v-1}^{(k)},
C_{v+1}^{(k)},\dots,C_{n-k}^{(k)}
\right\}.
\]</span></p>
<p>Thus, <span class="math inline">\((\mathcal{C}^{(0)}, \mathcal{C}^{(1)}, \dots, \mathcal{C}^{(n-1)})\)</span>
form a sequence of <em>nested</em> partitions of
the input dataset
with the last level being just one big cluster,
<span class="math inline">\(\mathcal{C}^{(n-1)}=\left\{ \{\mathbf{x}_{1,\cdot},\mathbf{x}_{2,\cdot},\dots,\mathbf{x}_{n,\cdot}\} \right\}\)</span>.</p>
<div style="margin-top: 1em">

</div>
<p>There is one component missing – how to determine the pair
of clusters <span class="math inline">\(C_u^{(k)}\)</span> and <span class="math inline">\(C_v^{(k)}\)</span> to be merged with each other
at the <span class="math inline">\(k\)</span>-th iteration?
Of course this will be expressed as some optimisation problem (although this time,
a simple one)! The decision will be based on:
<span class="math display">\[
\mathrm{arg}\min_{u &lt; v} d^*(C_u^{(k)}, C_v^{(k)}),
\]</span>
where <span class="math inline">\(d^*(C_u^{(k)}, C_v^{(k)})\)</span> is the <em>distance</em> between two clusters
<span class="math inline">\(C_u^{(k)}\)</span> and <span class="math inline">\(C_v^{(k)}\)</span>.</p>
<p>Note that we usually only consider the distances between <em>individual points</em>,
not sets of points. Hence, <span class="math inline">\(d^*\)</span> must be a suitable extension
of a pointwise distance <span class="math inline">\(d\)</span> (usually the Euclidean metric)
to whole sets.</p>
<p>We will assume that <span class="math inline">\(d^*(\{\mathbf{x}_{i,\cdot}\},\{\mathbf{x}_{j,\cdot}\})= d(\mathbf{x}_{i,\cdot},\mathbf{x}_{j,\cdot})\)</span>, i.e., the distance between
singleton clusters is the same as the distance between the points themselves.
As far as more populous point groups are concerned, there are many popular
choices of <span class="math inline">\(d^*\)</span> (which in the context of hierarchical clustering we call
<em>linkage functions</em>):</p>
<ul>
<li><p>single linkage:</p>
<p><span class="math display">\[
  d_\text{S}^*(C_u^{(k)}, C_v^{(k)}) =
  \min_{\mathbf{x}_{i,\cdot}\in C_u^{(k)}, \mathbf{x}_{j,\cdot}\in C_v^{(k)}} d(\mathbf{x}_{i,\cdot},\mathbf{x}_{j,\cdot}),
  \]</span></p></li>
<li><p>complete linkage:</p>
<p><span class="math display">\[
  d_\text{C}^*(C_u^{(k)}, C_v^{(k)}) =
  \max_{\mathbf{x}_{i,\cdot}\in C_u^{(k)}, \mathbf{x}_{j,\cdot}\in C_v^{(k)}} d(\mathbf{x}_{i,\cdot},\mathbf{x}_{j,\cdot}),
  \]</span></p></li>
<li><p>average linkage:</p>
<p><span class="math display">\[
  d_\text{A}^*(C_u^{(k)}, C_v^{(k)}) =
  \frac{1}{|C_u^{(k)}| |C_v^{(k)}|} \sum_{\mathbf{x}_{i,\cdot}\in C_u^{(k)}}\sum_{\mathbf{x}_{j,\cdot}\in C_v^{(k)}} d(\mathbf{x}_{i,\cdot},\mathbf{x}_{j,\cdot}).
  \]</span></p></li>
</ul>
<p>An illustration of the way different linkages are computed
is given in Figure <a href="agglomerative-hierarchical-clustering.html#fig:linkages">3</a>.</p>
<div class="figure">
<img src="02-hclust-figures/linkages-1.svg" alt="Figure 3: In single linkage, we find the closest pair of points; in complete linkage, we seek the pair furthest away from each other; in average linkage, we determine the arithmetic mean of all pairwise distances" id="fig:linkages" />
<p class="caption">Figure 3: In single linkage, we find the closest pair of points; in complete linkage, we seek the pair furthest away from each other; in average linkage, we determine the arithmetic mean of all pairwise distances</p>
</div>
<div style="margin-top: 1em">

</div>
<p>Assuming <span class="math inline">\(d_\text{S}^*\)</span>, <span class="math inline">\(d_\text{C}^*\)</span> or <span class="math inline">\(d_\text{A}^*\)</span>
in the aforementioned procedure leads to single, complete or average
linkage-based agglomerative hierarchical clustering algorithms,
respectively
(referred to as single linkage etc. for brevity).</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb40-1" title="1">hs &lt;-<span class="st"> </span><span class="kw">hclust</span>(D, <span class="dt">method=</span><span class="st">&quot;single&quot;</span>)</a>
<a class="sourceLine" id="cb40-2" title="2">hc &lt;-<span class="st"> </span><span class="kw">hclust</span>(D, <span class="dt">method=</span><span class="st">&quot;complete&quot;</span>)</a>
<a class="sourceLine" id="cb40-3" title="3">ha &lt;-<span class="st"> </span><span class="kw">hclust</span>(D, <span class="dt">method=</span><span class="st">&quot;average&quot;</span>)</a></code></pre></div>
<p>Figure <a href="agglomerative-hierarchical-clustering.html#fig:linkages_hier52">4</a> compares the 5-, 4- and 3-partitions
obtained by applying the 3 above linkages. Note that it’s in very nature of
the single linkage algorithm that it’s highly sensitive to outliers.</p>
<div class="figure">
<img src="02-hclust-figures/linkages_hier52-1.svg" alt="Figure 4: 3 cuts of 3 different hierarchies" id="fig:linkages_hier52" />
<p class="caption">Figure 4: 3 cuts of 3 different hierarchies</p>
</div>
</div>
<div id="cluster-dendrograms" class="section level3">
<h3><span class="header-section-number">2.1.4</span> Cluster Dendrograms</h3>
<p>A <em>dendrogram</em> (which we can plot by calling <code>plot(h)</code>, where <code>h</code> is
the result returned by <code>hclust()</code>) depicts the distances
(as defined by the linkage function) between the clusters merged at every stage
of the agglomerative procedure.
This can provide us with some insight into the underlying data structure
as well as with hits about at which level the tree could be cut.</p>
<p>Figure <a href="agglomerative-hierarchical-clustering.html#fig:dendrograms">5</a> depicts the three dendrograms
that correspond to the clusterings obtained by applying different linkages.
Each tree has 150 leaves (at the bottom) that represent the 150 points
in our example dataset. Each “edge” (joint) represents a group of points
being merged. For instance, the very top joint in the middle subfigure
is located at height of <span class="math inline">\(\simeq 6\)</span>, which is exactly the
maximal pairwise distance (complete linkage) between the points
in the last two last clusters.</p>
<div class="figure">
<img src="02-hclust-figures/dendrograms-1.svg" alt="Figure 5: Cluster dendrograms for the single, complete and average linkages" id="fig:dendrograms" />
<p class="caption">Figure 5: Cluster dendrograms for the single, complete and average linkages</p>
</div>
</div>
</div>
<div id="exercises" class="section level2">
<h2><span class="header-section-number">2.2</span> Exercises</h2>
<p>TODO: reuse from the K-means chapter</p>
</div>
<div id="outro" class="section level2">
<h2><span class="header-section-number">2.3</span> Outro</h2>
<div id="remarks" class="section level3">
<h3><span class="header-section-number">2.3.1</span> Remarks</h3>
<p>….</p>
</div>
<div id="further-reading" class="section level3">
<h3><span class="header-section-number">2.3.2</span> Further Reading</h3>
<p>…</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="classification-and-regression-with-k-nearest-neighbours.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": "lmlcr.pdf",
"toc": {
"collapse": "subsection",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
