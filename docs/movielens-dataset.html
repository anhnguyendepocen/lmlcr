<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>9.3 MovieLens Dataset (*) | Lightweight Machine Learning Classics with R</title>
  <meta name="description" content="Explore some of the most fundamental algorithms which have stood the test of time and provide the basis for innovative solutions in data-driven AI. Learn how to use the R language for implementing various stages of data processing and modelling activities. Appreciate mathematics as the universal language for formalising data-intense problems and communicating their solutions. The book is for you if you’re yet to be fluent with university-level linear algebra, calculus and probability theory or you’ve forgotten all the maths you’ve ever learned, and are seeking a gentle, yet thorough, introduction to the topic." />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="9.3 MovieLens Dataset (*) | Lightweight Machine Learning Classics with R" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://lmlcr.gagolewski.com" />
  
  <meta property="og:description" content="Explore some of the most fundamental algorithms which have stood the test of time and provide the basis for innovative solutions in data-driven AI. Learn how to use the R language for implementing various stages of data processing and modelling activities. Appreciate mathematics as the universal language for formalising data-intense problems and communicating their solutions. The book is for you if you’re yet to be fluent with university-level linear algebra, calculus and probability theory or you’ve forgotten all the maths you’ve ever learned, and are seeking a gentle, yet thorough, introduction to the topic." />
  <meta name="github-repo" content="gagolews/lmlcr" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="9.3 MovieLens Dataset (*) | Lightweight Machine Learning Classics with R" />
  
  <meta name="twitter:description" content="Explore some of the most fundamental algorithms which have stood the test of time and provide the basis for innovative solutions in data-driven AI. Learn how to use the R language for implementing various stages of data processing and modelling activities. Appreciate mathematics as the universal language for formalising data-intense problems and communicating their solutions. The book is for you if you’re yet to be fluent with university-level linear algebra, calculus and probability theory or you’ve forgotten all the maths you’ve ever learned, and are seeking a gentle, yet thorough, introduction to the topic." />
  

<meta name="author" content="Marek Gagolewski" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="collaborative-filtering.html"/>
<link rel="next" href="outro-8.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li style='font-style: italic' ><a href="./">LMLCR</a></li>
<li style='font-size: smaller' ><a href="https://www.gagolewski.com">Marek Gagolewski</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>{</a></li>
<li class="chapter" data-level="1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>1</b> Simple Linear Regression</a><ul>
<li class="chapter" data-level="1.1" data-path="machine-learning.html"><a href="machine-learning.html"><i class="fa fa-check"></i><b>1.1</b> Machine Learning</a><ul>
<li class="chapter" data-level="1.1.1" data-path="machine-learning.html"><a href="machine-learning.html#what-is-machine-learning"><i class="fa fa-check"></i><b>1.1.1</b> What is Machine Learning?</a></li>
<li class="chapter" data-level="1.1.2" data-path="machine-learning.html"><a href="machine-learning.html#main-types-of-machine-learning-problems"><i class="fa fa-check"></i><b>1.1.2</b> Main Types of Machine Learning Problems</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="supervised-learning.html"><a href="supervised-learning.html"><i class="fa fa-check"></i><b>1.2</b> Supervised Learning</a><ul>
<li class="chapter" data-level="1.2.1" data-path="supervised-learning.html"><a href="supervised-learning.html#formalism"><i class="fa fa-check"></i><b>1.2.1</b> Formalism</a></li>
<li class="chapter" data-level="1.2.2" data-path="supervised-learning.html"><a href="supervised-learning.html#desired-outputs"><i class="fa fa-check"></i><b>1.2.2</b> Desired Outputs</a></li>
<li class="chapter" data-level="1.2.3" data-path="supervised-learning.html"><a href="supervised-learning.html#types-of-supervised-learning-problems"><i class="fa fa-check"></i><b>1.2.3</b> Types of Supervised Learning Problems</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="simple-regression.html"><a href="simple-regression.html"><i class="fa fa-check"></i><b>1.3</b> Simple Regression</a><ul>
<li class="chapter" data-level="1.3.1" data-path="simple-regression.html"><a href="simple-regression.html#introduction"><i class="fa fa-check"></i><b>1.3.1</b> Introduction</a></li>
<li class="chapter" data-level="1.3.2" data-path="simple-regression.html"><a href="simple-regression.html#search-space-and-objective"><i class="fa fa-check"></i><b>1.3.2</b> Search Space and Objective</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="simple-linear-regression-1.html"><a href="simple-linear-regression-1.html"><i class="fa fa-check"></i><b>1.4</b> Simple Linear Regression</a><ul>
<li class="chapter" data-level="1.4.1" data-path="simple-linear-regression-1.html"><a href="simple-linear-regression-1.html#introduction-1"><i class="fa fa-check"></i><b>1.4.1</b> Introduction</a></li>
<li class="chapter" data-level="1.4.2" data-path="simple-linear-regression-1.html"><a href="simple-linear-regression-1.html#solution-in-r"><i class="fa fa-check"></i><b>1.4.2</b> Solution in R</a></li>
<li class="chapter" data-level="1.4.3" data-path="simple-linear-regression-1.html"><a href="simple-linear-regression-1.html#derivation-of-the-solution"><i class="fa fa-check"></i><b>1.4.3</b> Derivation of the Solution (**)</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="outro.html"><a href="outro.html"><i class="fa fa-check"></i><b>1.5</b> Outro</a><ul>
<li class="chapter" data-level="1.5.1" data-path="outro.html"><a href="outro.html#remarks"><i class="fa fa-check"></i><b>1.5.1</b> Remarks</a></li>
<li class="chapter" data-level="1.5.2" data-path="outro.html"><a href="outro.html#further-reading"><i class="fa fa-check"></i><b>1.5.2</b> Further Reading</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="multiple-regression.html"><a href="multiple-regression.html"><i class="fa fa-check"></i><b>2</b> Multiple Regression</a><ul>
<li class="chapter" data-level="2.1" data-path="introduction-2.html"><a href="introduction-2.html"><i class="fa fa-check"></i><b>2.1</b> Introduction</a><ul>
<li class="chapter" data-level="2.1.1" data-path="introduction-2.html"><a href="introduction-2.html#formalism-1"><i class="fa fa-check"></i><b>2.1.1</b> Formalism</a></li>
<li class="chapter" data-level="2.1.2" data-path="introduction-2.html"><a href="introduction-2.html#simple-linear-regression---recap"><i class="fa fa-check"></i><b>2.1.2</b> Simple Linear Regression - Recap</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html"><i class="fa fa-check"></i><b>2.2</b> Multiple Linear Regression</a><ul>
<li class="chapter" data-level="2.2.1" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#problem-formulation"><i class="fa fa-check"></i><b>2.2.1</b> Problem Formulation</a></li>
<li class="chapter" data-level="2.2.2" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#fitting-a-linear-model-in-r"><i class="fa fa-check"></i><b>2.2.2</b> Fitting a Linear Model in R</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="finding-the-best-model.html"><a href="finding-the-best-model.html"><i class="fa fa-check"></i><b>2.3</b> Finding the Best Model</a><ul>
<li class="chapter" data-level="2.3.1" data-path="finding-the-best-model.html"><a href="finding-the-best-model.html#model-diagnostics"><i class="fa fa-check"></i><b>2.3.1</b> Model Diagnostics</a></li>
<li class="chapter" data-level="2.3.2" data-path="finding-the-best-model.html"><a href="finding-the-best-model.html#variable-selection"><i class="fa fa-check"></i><b>2.3.2</b> Variable Selection</a></li>
<li class="chapter" data-level="2.3.3" data-path="finding-the-best-model.html"><a href="finding-the-best-model.html#variable-transformation"><i class="fa fa-check"></i><b>2.3.3</b> Variable Transformation</a></li>
<li class="chapter" data-level="2.3.4" data-path="finding-the-best-model.html"><a href="finding-the-best-model.html#predictive-vs.descriptive-power"><i class="fa fa-check"></i><b>2.3.4</b> Predictive vs. Descriptive Power</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="outro-1.html"><a href="outro-1.html"><i class="fa fa-check"></i><b>2.4</b> Outro</a><ul>
<li class="chapter" data-level="2.4.1" data-path="outro-1.html"><a href="outro-1.html#remarks-1"><i class="fa fa-check"></i><b>2.4.1</b> Remarks</a></li>
<li class="chapter" data-level="2.4.2" data-path="outro-1.html"><a href="outro-1.html#other-methods-for-regression"><i class="fa fa-check"></i><b>2.4.2</b> Other Methods for Regression</a></li>
<li class="chapter" data-level="2.4.3" data-path="outro-1.html"><a href="outro-1.html#derivation-of-the-solution-1"><i class="fa fa-check"></i><b>2.4.3</b> Derivation of the Solution (**)</a></li>
<li class="chapter" data-level="2.4.4" data-path="outro-1.html"><a href="outro-1.html#solution-in-matrix-form"><i class="fa fa-check"></i><b>2.4.4</b> Solution in Matrix Form (***)</a></li>
<li class="chapter" data-level="2.4.5" data-path="outro-1.html"><a href="outro-1.html#pearsons-r-in-matrix-form"><i class="fa fa-check"></i><b>2.4.5</b> Pearson’s r in Matrix Form (**)</a></li>
<li class="chapter" data-level="2.4.6" data-path="outro-1.html"><a href="outro-1.html#further-reading-1"><i class="fa fa-check"></i><b>2.4.6</b> Further Reading</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="classification-with-k-nearest-neighbours.html"><a href="classification-with-k-nearest-neighbours.html"><i class="fa fa-check"></i><b>3</b> Classification with K-Nearest Neighbours</a><ul>
<li class="chapter" data-level="3.1" data-path="introduction-3.html"><a href="introduction-3.html"><i class="fa fa-check"></i><b>3.1</b> Introduction</a><ul>
<li class="chapter" data-level="3.1.1" data-path="introduction-3.html"><a href="introduction-3.html#classification-task"><i class="fa fa-check"></i><b>3.1.1</b> Classification Task</a></li>
<li class="chapter" data-level="3.1.2" data-path="introduction-3.html"><a href="introduction-3.html#factor-data-type"><i class="fa fa-check"></i><b>3.1.2</b> Factor Data Type</a></li>
<li class="chapter" data-level="3.1.3" data-path="introduction-3.html"><a href="introduction-3.html#data"><i class="fa fa-check"></i><b>3.1.3</b> Data</a></li>
<li class="chapter" data-level="3.1.4" data-path="introduction-3.html"><a href="introduction-3.html#training-and-test-sets"><i class="fa fa-check"></i><b>3.1.4</b> Training and Test Sets</a></li>
<li class="chapter" data-level="3.1.5" data-path="introduction-3.html"><a href="introduction-3.html#discussed-methods"><i class="fa fa-check"></i><b>3.1.5</b> Discussed Methods</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="k-nearest-neighbour-classifier.html"><a href="k-nearest-neighbour-classifier.html"><i class="fa fa-check"></i><b>3.2</b> K-nearest Neighbour Classifier</a><ul>
<li class="chapter" data-level="3.2.1" data-path="k-nearest-neighbour-classifier.html"><a href="k-nearest-neighbour-classifier.html#introduction-4"><i class="fa fa-check"></i><b>3.2.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2.2" data-path="k-nearest-neighbour-classifier.html"><a href="k-nearest-neighbour-classifier.html#example-in-r"><i class="fa fa-check"></i><b>3.2.2</b> Example in R</a></li>
<li class="chapter" data-level="3.2.3" data-path="k-nearest-neighbour-classifier.html"><a href="k-nearest-neighbour-classifier.html#different-metrics"><i class="fa fa-check"></i><b>3.2.3</b> Different Metrics (*)</a></li>
<li class="chapter" data-level="3.2.4" data-path="k-nearest-neighbour-classifier.html"><a href="k-nearest-neighbour-classifier.html#standardisation-of-independent-variables"><i class="fa fa-check"></i><b>3.2.4</b> Standardisation of Independent Variables</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="implementing-a-k-nn-classifier.html"><a href="implementing-a-k-nn-classifier.html"><i class="fa fa-check"></i><b>3.3</b> Implementing a K-NN Classifier (*)</a><ul>
<li class="chapter" data-level="3.3.1" data-path="implementing-a-k-nn-classifier.html"><a href="implementing-a-k-nn-classifier.html#main-routine"><i class="fa fa-check"></i><b>3.3.1</b> Main Routine (*)</a></li>
<li class="chapter" data-level="3.3.2" data-path="implementing-a-k-nn-classifier.html"><a href="implementing-a-k-nn-classifier.html#mode"><i class="fa fa-check"></i><b>3.3.2</b> Mode</a></li>
<li class="chapter" data-level="3.3.3" data-path="implementing-a-k-nn-classifier.html"><a href="implementing-a-k-nn-classifier.html#nn-search-routines"><i class="fa fa-check"></i><b>3.3.3</b> NN Search Routines (*)</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="outro-2.html"><a href="outro-2.html"><i class="fa fa-check"></i><b>3.4</b> Outro</a><ul>
<li class="chapter" data-level="3.4.1" data-path="outro-2.html"><a href="outro-2.html#remarks-2"><i class="fa fa-check"></i><b>3.4.1</b> Remarks</a></li>
<li class="chapter" data-level="3.4.2" data-path="outro-2.html"><a href="outro-2.html#side-note-k-nn-regression"><i class="fa fa-check"></i><b>3.4.2</b> Side Note: K-NN Regression</a></li>
<li class="chapter" data-level="3.4.3" data-path="outro-2.html"><a href="outro-2.html#further-reading-2"><i class="fa fa-check"></i><b>3.4.3</b> Further Reading</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="classification-with-trees-and-linear-models.html"><a href="classification-with-trees-and-linear-models.html"><i class="fa fa-check"></i><b>4</b> Classification with Trees and Linear Models</a><ul>
<li class="chapter" data-level="4.1" data-path="introduction-5.html"><a href="introduction-5.html"><i class="fa fa-check"></i><b>4.1</b> Introduction</a><ul>
<li class="chapter" data-level="4.1.1" data-path="introduction-5.html"><a href="introduction-5.html#classification-task-1"><i class="fa fa-check"></i><b>4.1.1</b> Classification Task</a></li>
<li class="chapter" data-level="4.1.2" data-path="introduction-5.html"><a href="introduction-5.html#data-1"><i class="fa fa-check"></i><b>4.1.2</b> Data</a></li>
<li class="chapter" data-level="4.1.3" data-path="introduction-5.html"><a href="introduction-5.html#discussed-methods-1"><i class="fa fa-check"></i><b>4.1.3</b> Discussed Methods</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="model-assessment-and-selection.html"><a href="model-assessment-and-selection.html"><i class="fa fa-check"></i><b>4.2</b> Model Assessment and Selection</a><ul>
<li class="chapter" data-level="4.2.1" data-path="model-assessment-and-selection.html"><a href="model-assessment-and-selection.html#performance-metrics"><i class="fa fa-check"></i><b>4.2.1</b> Performance Metrics</a></li>
<li class="chapter" data-level="4.2.2" data-path="model-assessment-and-selection.html"><a href="model-assessment-and-selection.html#how-to-choose-k-for-k-nn-classification"><i class="fa fa-check"></i><b>4.2.2</b> How to Choose K for K-NN Classification?</a></li>
<li class="chapter" data-level="4.2.3" data-path="model-assessment-and-selection.html"><a href="model-assessment-and-selection.html#training-validation-and-test-sets"><i class="fa fa-check"></i><b>4.2.3</b> Training, Validation and Test sets</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="decision-trees.html"><a href="decision-trees.html"><i class="fa fa-check"></i><b>4.3</b> Decision Trees</a><ul>
<li class="chapter" data-level="4.3.1" data-path="decision-trees.html"><a href="decision-trees.html#introduction-6"><i class="fa fa-check"></i><b>4.3.1</b> Introduction</a></li>
<li class="chapter" data-level="4.3.2" data-path="decision-trees.html"><a href="decision-trees.html#example-in-r-1"><i class="fa fa-check"></i><b>4.3.2</b> Example in R</a></li>
<li class="chapter" data-level="4.3.3" data-path="decision-trees.html"><a href="decision-trees.html#a-note-on-decision-tree-learning"><i class="fa fa-check"></i><b>4.3.3</b> A Note on Decision Tree Learning</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="binary-logistic-regression.html"><a href="binary-logistic-regression.html"><i class="fa fa-check"></i><b>4.4</b> Binary Logistic Regression</a><ul>
<li class="chapter" data-level="4.4.1" data-path="binary-logistic-regression.html"><a href="binary-logistic-regression.html#motivation"><i class="fa fa-check"></i><b>4.4.1</b> Motivation</a></li>
<li class="chapter" data-level="4.4.2" data-path="binary-logistic-regression.html"><a href="binary-logistic-regression.html#logistic-model"><i class="fa fa-check"></i><b>4.4.2</b> Logistic Model</a></li>
<li class="chapter" data-level="4.4.3" data-path="binary-logistic-regression.html"><a href="binary-logistic-regression.html#example-in-r-2"><i class="fa fa-check"></i><b>4.4.3</b> Example in R</a></li>
<li class="chapter" data-level="4.4.4" data-path="binary-logistic-regression.html"><a href="binary-logistic-regression.html#loss-function"><i class="fa fa-check"></i><b>4.4.4</b> Loss Function</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="outro-3.html"><a href="outro-3.html"><i class="fa fa-check"></i><b>4.5</b> Outro</a><ul>
<li class="chapter" data-level="4.5.1" data-path="outro-3.html"><a href="outro-3.html#remarks-3"><i class="fa fa-check"></i><b>4.5.1</b> Remarks</a></li>
<li class="chapter" data-level="4.5.2" data-path="outro-3.html"><a href="outro-3.html#further-reading-3"><i class="fa fa-check"></i><b>4.5.2</b> Further Reading</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="neural-networks.html"><a href="neural-networks.html"><i class="fa fa-check"></i><b>5</b> Neural Networks</a><ul>
<li class="chapter" data-level="5.1" data-path="introduction-7.html"><a href="introduction-7.html"><i class="fa fa-check"></i><b>5.1</b> Introduction</a><ul>
<li class="chapter" data-level="5.1.1" data-path="introduction-7.html"><a href="introduction-7.html#binary-logistic-regression-recap"><i class="fa fa-check"></i><b>5.1.1</b> Binary Logistic Regression: Recap</a></li>
<li class="chapter" data-level="5.1.2" data-path="introduction-7.html"><a href="introduction-7.html#data-2"><i class="fa fa-check"></i><b>5.1.2</b> Data</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="multinomial-logistic-regression.html"><a href="multinomial-logistic-regression.html"><i class="fa fa-check"></i><b>5.2</b> Multinomial Logistic Regression</a><ul>
<li class="chapter" data-level="5.2.1" data-path="multinomial-logistic-regression.html"><a href="multinomial-logistic-regression.html#a-note-on-data-representation"><i class="fa fa-check"></i><b>5.2.1</b> A Note on Data Representation</a></li>
<li class="chapter" data-level="5.2.2" data-path="multinomial-logistic-regression.html"><a href="multinomial-logistic-regression.html#extending-logistic-regression"><i class="fa fa-check"></i><b>5.2.2</b> Extending Logistic Regression</a></li>
<li class="chapter" data-level="5.2.3" data-path="multinomial-logistic-regression.html"><a href="multinomial-logistic-regression.html#softmax-function"><i class="fa fa-check"></i><b>5.2.3</b> Softmax Function</a></li>
<li class="chapter" data-level="5.2.4" data-path="multinomial-logistic-regression.html"><a href="multinomial-logistic-regression.html#one-hot-encoding-and-decoding"><i class="fa fa-check"></i><b>5.2.4</b> One-Hot Encoding and Decoding</a></li>
<li class="chapter" data-level="5.2.5" data-path="multinomial-logistic-regression.html"><a href="multinomial-logistic-regression.html#cross-entropy-revisited"><i class="fa fa-check"></i><b>5.2.5</b> Cross-entropy Revisited</a></li>
<li class="chapter" data-level="5.2.6" data-path="multinomial-logistic-regression.html"><a href="multinomial-logistic-regression.html#problem-formulation-in-matrix-form"><i class="fa fa-check"></i><b>5.2.6</b> Problem Formulation in Matrix Form (**)</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="artificial-neural-networks.html"><a href="artificial-neural-networks.html"><i class="fa fa-check"></i><b>5.3</b> Artificial Neural Networks</a><ul>
<li class="chapter" data-level="5.3.1" data-path="artificial-neural-networks.html"><a href="artificial-neural-networks.html#artificial-neuron"><i class="fa fa-check"></i><b>5.3.1</b> Artificial Neuron</a></li>
<li class="chapter" data-level="5.3.2" data-path="artificial-neural-networks.html"><a href="artificial-neural-networks.html#logistic-regression-as-a-neural-network"><i class="fa fa-check"></i><b>5.3.2</b> Logistic Regression as a Neural Network</a></li>
<li class="chapter" data-level="5.3.3" data-path="artificial-neural-networks.html"><a href="artificial-neural-networks.html#example-in-r-3"><i class="fa fa-check"></i><b>5.3.3</b> Example in R</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="deep-neural-networks.html"><a href="deep-neural-networks.html"><i class="fa fa-check"></i><b>5.4</b> Deep Neural Networks</a><ul>
<li class="chapter" data-level="5.4.1" data-path="deep-neural-networks.html"><a href="deep-neural-networks.html#introduction-8"><i class="fa fa-check"></i><b>5.4.1</b> Introduction</a></li>
<li class="chapter" data-level="5.4.2" data-path="deep-neural-networks.html"><a href="deep-neural-networks.html#activation-functions"><i class="fa fa-check"></i><b>5.4.2</b> Activation Functions</a></li>
<li class="chapter" data-level="5.4.3" data-path="deep-neural-networks.html"><a href="deep-neural-networks.html#example-in-r---2-layers"><i class="fa fa-check"></i><b>5.4.3</b> Example in R - 2 Layers</a></li>
<li class="chapter" data-level="5.4.4" data-path="deep-neural-networks.html"><a href="deep-neural-networks.html#example-in-r---6-layers"><i class="fa fa-check"></i><b>5.4.4</b> Example in R - 6 Layers</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="preprocessing-of-data.html"><a href="preprocessing-of-data.html"><i class="fa fa-check"></i><b>5.5</b> Preprocessing of Data</a><ul>
<li class="chapter" data-level="5.5.1" data-path="preprocessing-of-data.html"><a href="preprocessing-of-data.html#introduction-9"><i class="fa fa-check"></i><b>5.5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.5.2" data-path="preprocessing-of-data.html"><a href="preprocessing-of-data.html#image-deskewing"><i class="fa fa-check"></i><b>5.5.2</b> Image Deskewing</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="outro-4.html"><a href="outro-4.html"><i class="fa fa-check"></i><b>5.6</b> Outro</a><ul>
<li class="chapter" data-level="5.6.1" data-path="outro-4.html"><a href="outro-4.html#remarks-4"><i class="fa fa-check"></i><b>5.6.1</b> Remarks</a></li>
<li class="chapter" data-level="5.6.2" data-path="outro-4.html"><a href="outro-4.html#beyond-mnist"><i class="fa fa-check"></i><b>5.6.2</b> Beyond MNIST</a></li>
<li class="chapter" data-level="5.6.3" data-path="outro-4.html"><a href="outro-4.html#further-reading-4"><i class="fa fa-check"></i><b>5.6.3</b> Further Reading</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="optimisation-with-iterative-algorithms.html"><a href="optimisation-with-iterative-algorithms.html"><i class="fa fa-check"></i><b>6</b> Optimisation with Iterative Algorithms</a><ul>
<li class="chapter" data-level="6.1" data-path="introduction-10.html"><a href="introduction-10.html"><i class="fa fa-check"></i><b>6.1</b> Introduction</a><ul>
<li class="chapter" data-level="6.1.1" data-path="introduction-10.html"><a href="introduction-10.html#optimisation-problem"><i class="fa fa-check"></i><b>6.1.1</b> Optimisation Problem</a></li>
<li class="chapter" data-level="6.1.2" data-path="introduction-10.html"><a href="introduction-10.html#example-optimisation-problems-in-machine-learning"><i class="fa fa-check"></i><b>6.1.2</b> Example Optimisation Problems in Machine Learning</a></li>
<li class="chapter" data-level="6.1.3" data-path="introduction-10.html"><a href="introduction-10.html#types-of-minima-and-maxima"><i class="fa fa-check"></i><b>6.1.3</b> Types of Minima and Maxima</a></li>
<li class="chapter" data-level="6.1.4" data-path="introduction-10.html"><a href="introduction-10.html#example-objective-over-a-2d-domain"><i class="fa fa-check"></i><b>6.1.4</b> Example Objective over a 2D Domain</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="iterative-methods.html"><a href="iterative-methods.html"><i class="fa fa-check"></i><b>6.2</b> Iterative Methods</a><ul>
<li class="chapter" data-level="6.2.1" data-path="iterative-methods.html"><a href="iterative-methods.html#introduction-11"><i class="fa fa-check"></i><b>6.2.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2.2" data-path="iterative-methods.html"><a href="iterative-methods.html#example-in-r-4"><i class="fa fa-check"></i><b>6.2.2</b> Example in R</a></li>
<li class="chapter" data-level="6.2.3" data-path="iterative-methods.html"><a href="iterative-methods.html#convergence-to-local-optima"><i class="fa fa-check"></i><b>6.2.3</b> Convergence to Local Optima</a></li>
<li class="chapter" data-level="6.2.4" data-path="iterative-methods.html"><a href="iterative-methods.html#random-restarts"><i class="fa fa-check"></i><b>6.2.4</b> Random Restarts</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="gradient-descent.html"><a href="gradient-descent.html"><i class="fa fa-check"></i><b>6.3</b> Gradient Descent</a><ul>
<li class="chapter" data-level="6.3.1" data-path="gradient-descent.html"><a href="gradient-descent.html#function-gradient"><i class="fa fa-check"></i><b>6.3.1</b> Function Gradient (*)</a></li>
<li class="chapter" data-level="6.3.2" data-path="gradient-descent.html"><a href="gradient-descent.html#three-facts-on-the-gradient"><i class="fa fa-check"></i><b>6.3.2</b> Three Facts on the Gradient</a></li>
<li class="chapter" data-level="6.3.3" data-path="gradient-descent.html"><a href="gradient-descent.html#gradient-descent-algorithm-gd"><i class="fa fa-check"></i><b>6.3.3</b> Gradient Descent Algorithm (GD)</a></li>
<li class="chapter" data-level="6.3.4" data-path="gradient-descent.html"><a href="gradient-descent.html#example-mnist"><i class="fa fa-check"></i><b>6.3.4</b> Example: MNIST</a></li>
<li class="chapter" data-level="6.3.5" data-path="gradient-descent.html"><a href="gradient-descent.html#stochastic-gradient-descent-sgd"><i class="fa fa-check"></i><b>6.3.5</b> Stochastic Gradient Descent (SGD)</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="outro-5.html"><a href="outro-5.html"><i class="fa fa-check"></i><b>6.4</b> Outro</a><ul>
<li class="chapter" data-level="6.4.1" data-path="outro-5.html"><a href="outro-5.html#remarks-5"><i class="fa fa-check"></i><b>6.4.1</b> Remarks</a></li>
<li class="chapter" data-level="6.4.2" data-path="outro-5.html"><a href="outro-5.html#optimisers-in-keras"><i class="fa fa-check"></i><b>6.4.2</b> Optimisers in Keras</a></li>
<li class="chapter" data-level="6.4.3" data-path="outro-5.html"><a href="outro-5.html#note-on-search-spaces"><i class="fa fa-check"></i><b>6.4.3</b> Note on Search Spaces</a></li>
<li class="chapter" data-level="6.4.4" data-path="outro-5.html"><a href="outro-5.html#further-reading-5"><i class="fa fa-check"></i><b>6.4.4</b> Further Reading</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="clustering.html"><a href="clustering.html"><i class="fa fa-check"></i><b>7</b> Clustering</a><ul>
<li class="chapter" data-level="7.1" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html"><i class="fa fa-check"></i><b>7.1</b> Unsupervised Learning</a><ul>
<li class="chapter" data-level="7.1.1" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#introduction-12"><i class="fa fa-check"></i><b>7.1.1</b> Introduction</a></li>
<li class="chapter" data-level="7.1.2" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#main-types-of-unsupervised-learning-problems"><i class="fa fa-check"></i><b>7.1.2</b> Main Types of Unsupervised Learning Problems</a></li>
<li class="chapter" data-level="7.1.3" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#clustering-1"><i class="fa fa-check"></i><b>7.1.3</b> Clustering</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="k-means-clustering.html"><a href="k-means-clustering.html"><i class="fa fa-check"></i><b>7.2</b> K-means Clustering</a><ul>
<li class="chapter" data-level="7.2.1" data-path="k-means-clustering.html"><a href="k-means-clustering.html#example-in-r-5"><i class="fa fa-check"></i><b>7.2.1</b> Example in R</a></li>
<li class="chapter" data-level="7.2.2" data-path="k-means-clustering.html"><a href="k-means-clustering.html#problem-statement"><i class="fa fa-check"></i><b>7.2.2</b> Problem Statement</a></li>
<li class="chapter" data-level="7.2.3" data-path="k-means-clustering.html"><a href="k-means-clustering.html#algorithms-for-the-k-means-problem"><i class="fa fa-check"></i><b>7.2.3</b> Algorithms for the K-means Problem</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="hierarchical-methods.html"><a href="hierarchical-methods.html"><i class="fa fa-check"></i><b>7.3</b> Hierarchical Methods</a><ul>
<li class="chapter" data-level="7.3.1" data-path="hierarchical-methods.html"><a href="hierarchical-methods.html#introduction-13"><i class="fa fa-check"></i><b>7.3.1</b> Introduction</a></li>
<li class="chapter" data-level="7.3.2" data-path="hierarchical-methods.html"><a href="hierarchical-methods.html#example-in-r-6"><i class="fa fa-check"></i><b>7.3.2</b> Example in R</a></li>
<li class="chapter" data-level="7.3.3" data-path="hierarchical-methods.html"><a href="hierarchical-methods.html#agglomerative-hierarchical-clustering"><i class="fa fa-check"></i><b>7.3.3</b> Agglomerative Hierarchical Clustering</a></li>
<li class="chapter" data-level="7.3.4" data-path="hierarchical-methods.html"><a href="hierarchical-methods.html#linkage-functions"><i class="fa fa-check"></i><b>7.3.4</b> Linkage Functions</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="outro-6.html"><a href="outro-6.html"><i class="fa fa-check"></i><b>7.4</b> Outro</a><ul>
<li class="chapter" data-level="7.4.1" data-path="outro-6.html"><a href="outro-6.html#remarks-6"><i class="fa fa-check"></i><b>7.4.1</b> Remarks</a></li>
<li class="chapter" data-level="7.4.2" data-path="outro-6.html"><a href="outro-6.html#other-noteworthy-clustering-algorithms"><i class="fa fa-check"></i><b>7.4.2</b> Other Noteworthy Clustering Algorithms</a></li>
<li class="chapter" data-level="7.4.3" data-path="outro-6.html"><a href="outro-6.html#further-reading-6"><i class="fa fa-check"></i><b>7.4.3</b> Further Reading</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="optimisation-with-genetic-algorithms.html"><a href="optimisation-with-genetic-algorithms.html"><i class="fa fa-check"></i><b>8</b> Optimisation with Genetic Algorithms</a><ul>
<li class="chapter" data-level="8.1" data-path="introduction-14.html"><a href="introduction-14.html"><i class="fa fa-check"></i><b>8.1</b> Introduction</a><ul>
<li class="chapter" data-level="8.1.1" data-path="introduction-14.html"><a href="introduction-14.html#recap"><i class="fa fa-check"></i><b>8.1.1</b> Recap</a></li>
<li class="chapter" data-level="8.1.2" data-path="introduction-14.html"><a href="introduction-14.html#k-means-revisited"><i class="fa fa-check"></i><b>8.1.2</b> K-means Revisited</a></li>
<li class="chapter" data-level="8.1.3" data-path="introduction-14.html"><a href="introduction-14.html#optim-vs.kmeans"><i class="fa fa-check"></i><b>8.1.3</b> optim() vs. kmeans()</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="a-note-on-convex-optimisation.html"><a href="a-note-on-convex-optimisation.html"><i class="fa fa-check"></i><b>8.2</b> A Note on Convex Optimisation (*)</a><ul>
<li class="chapter" data-level="8.2.1" data-path="a-note-on-convex-optimisation.html"><a href="a-note-on-convex-optimisation.html#introduction-15"><i class="fa fa-check"></i><b>8.2.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2.2" data-path="a-note-on-convex-optimisation.html"><a href="a-note-on-convex-optimisation.html#convex-combinations"><i class="fa fa-check"></i><b>8.2.2</b> Convex Combinations (*)</a></li>
<li class="chapter" data-level="8.2.3" data-path="a-note-on-convex-optimisation.html"><a href="a-note-on-convex-optimisation.html#convex-functions"><i class="fa fa-check"></i><b>8.2.3</b> Convex Functions (*)</a></li>
<li class="chapter" data-level="8.2.4" data-path="a-note-on-convex-optimisation.html"><a href="a-note-on-convex-optimisation.html#examples"><i class="fa fa-check"></i><b>8.2.4</b> Examples</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="genetic-algorithms.html"><a href="genetic-algorithms.html"><i class="fa fa-check"></i><b>8.3</b> Genetic Algorithms</a><ul>
<li class="chapter" data-level="8.3.1" data-path="genetic-algorithms.html"><a href="genetic-algorithms.html#introduction-16"><i class="fa fa-check"></i><b>8.3.1</b> Introduction</a></li>
<li class="chapter" data-level="8.3.2" data-path="genetic-algorithms.html"><a href="genetic-algorithms.html#overview-of-the-method"><i class="fa fa-check"></i><b>8.3.2</b> Overview of the Method</a></li>
<li class="chapter" data-level="8.3.3" data-path="genetic-algorithms.html"><a href="genetic-algorithms.html#example-implementation---ga-for-k-means"><i class="fa fa-check"></i><b>8.3.3</b> Example Implementation - GA for K-means</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="outro-7.html"><a href="outro-7.html"><i class="fa fa-check"></i><b>8.4</b> Outro</a><ul>
<li class="chapter" data-level="8.4.1" data-path="outro-7.html"><a href="outro-7.html#remarks-7"><i class="fa fa-check"></i><b>8.4.1</b> Remarks</a></li>
<li class="chapter" data-level="8.4.2" data-path="outro-7.html"><a href="outro-7.html#further-reading-7"><i class="fa fa-check"></i><b>8.4.2</b> Further Reading</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="recommender-systems.html"><a href="recommender-systems.html"><i class="fa fa-check"></i><b>9</b> Recommender Systems</a><ul>
<li class="chapter" data-level="9.1" data-path="introduction-17.html"><a href="introduction-17.html"><i class="fa fa-check"></i><b>9.1</b> Introduction</a><ul>
<li class="chapter" data-level="9.1.1" data-path="introduction-17.html"><a href="introduction-17.html#what-is-a-recommender-system"><i class="fa fa-check"></i><b>9.1.1</b> What is a Recommender System?</a></li>
<li class="chapter" data-level="9.1.2" data-path="introduction-17.html"><a href="introduction-17.html#the-netflix-prize"><i class="fa fa-check"></i><b>9.1.2</b> The Netflix Prize</a></li>
<li class="chapter" data-level="9.1.3" data-path="introduction-17.html"><a href="introduction-17.html#main-approaches"><i class="fa fa-check"></i><b>9.1.3</b> Main Approaches</a></li>
<li class="chapter" data-level="9.1.4" data-path="introduction-17.html"><a href="introduction-17.html#formalism-2"><i class="fa fa-check"></i><b>9.1.4</b> Formalism</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="collaborative-filtering.html"><a href="collaborative-filtering.html"><i class="fa fa-check"></i><b>9.2</b> Collaborative Filtering</a><ul>
<li class="chapter" data-level="9.2.1" data-path="collaborative-filtering.html"><a href="collaborative-filtering.html#example"><i class="fa fa-check"></i><b>9.2.1</b> Example</a></li>
<li class="chapter" data-level="9.2.2" data-path="collaborative-filtering.html"><a href="collaborative-filtering.html#similarity-measures"><i class="fa fa-check"></i><b>9.2.2</b> Similarity Measures</a></li>
<li class="chapter" data-level="9.2.3" data-path="collaborative-filtering.html"><a href="collaborative-filtering.html#user-based-collaborative-filtering"><i class="fa fa-check"></i><b>9.2.3</b> User-Based Collaborative Filtering</a></li>
<li class="chapter" data-level="9.2.4" data-path="collaborative-filtering.html"><a href="collaborative-filtering.html#item-based-collaborative-filtering"><i class="fa fa-check"></i><b>9.2.4</b> Item-Based Collaborative Filtering</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="movielens-dataset.html"><a href="movielens-dataset.html"><i class="fa fa-check"></i><b>9.3</b> MovieLens Dataset (*)</a><ul>
<li class="chapter" data-level="9.3.1" data-path="movielens-dataset.html"><a href="movielens-dataset.html#dataset"><i class="fa fa-check"></i><b>9.3.1</b> Dataset</a></li>
<li class="chapter" data-level="9.3.2" data-path="movielens-dataset.html"><a href="movielens-dataset.html#data-cleansing"><i class="fa fa-check"></i><b>9.3.2</b> Data Cleansing</a></li>
<li class="chapter" data-level="9.3.3" data-path="movielens-dataset.html"><a href="movielens-dataset.html#item-item-similarities"><i class="fa fa-check"></i><b>9.3.3</b> Item-Item Similarities</a></li>
<li class="chapter" data-level="9.3.4" data-path="movielens-dataset.html"><a href="movielens-dataset.html#example-recommendations"><i class="fa fa-check"></i><b>9.3.4</b> Example Recommendations</a></li>
<li class="chapter" data-level="9.3.5" data-path="movielens-dataset.html"><a href="movielens-dataset.html#clustering-2"><i class="fa fa-check"></i><b>9.3.5</b> Clustering</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="outro-8.html"><a href="outro-8.html"><i class="fa fa-check"></i><b>9.4</b> Outro</a><ul>
<li class="chapter" data-level="9.4.1" data-path="outro-8.html"><a href="outro-8.html#remarks-8"><i class="fa fa-check"></i><b>9.4.1</b> Remarks</a></li>
<li class="chapter" data-level="9.4.2" data-path="outro-8.html"><a href="outro-8.html#issues"><i class="fa fa-check"></i><b>9.4.2</b> Issues</a></li>
<li class="chapter" data-level="9.4.3" data-path="outro-8.html"><a href="outro-8.html#further-reading-8"><i class="fa fa-check"></i><b>9.4.3</b> Further Reading</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="section-15.html"><a href="section-15.html"><i class="fa fa-check"></i>}</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="vector-algebra-in-r.html"><a href="vector-algebra-in-r.html"><i class="fa fa-check"></i><b>A</b> Vector Algebra in R</a><ul>
<li class="chapter" data-level="A.1" data-path="motivation-1.html"><a href="motivation-1.html"><i class="fa fa-check"></i><b>A.1</b> Motivation</a></li>
<li class="chapter" data-level="A.2" data-path="vector-scalar-operations.html"><a href="vector-scalar-operations.html"><i class="fa fa-check"></i><b>A.2</b> Vector-Scalar Operations</a></li>
<li class="chapter" data-level="A.3" data-path="vector-vector-operations.html"><a href="vector-vector-operations.html"><i class="fa fa-check"></i><b>A.3</b> Vector-Vector Operations</a></li>
<li class="chapter" data-level="A.4" data-path="other-vector-operations.html"><a href="other-vector-operations.html"><i class="fa fa-check"></i><b>A.4</b> Other Vector Operations</a></li>
<li class="chapter" data-level="A.5" data-path="further-reading-9.html"><a href="further-reading-9.html"><i class="fa fa-check"></i><b>A.5</b> Further Reading</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="matrix-algebra-in-r.html"><a href="matrix-algebra-in-r.html"><i class="fa fa-check"></i><b>B</b> Matrix Algebra in R</a><ul>
<li class="chapter" data-level="B.1" data-path="matrices.html"><a href="matrices.html"><i class="fa fa-check"></i><b>B.1</b> Matrices</a></li>
<li class="chapter" data-level="B.2" data-path="matrix-scalar-operations.html"><a href="matrix-scalar-operations.html"><i class="fa fa-check"></i><b>B.2</b> Matrix-Scalar Operations</a></li>
<li class="chapter" data-level="B.3" data-path="matrix-matrix-operations.html"><a href="matrix-matrix-operations.html"><i class="fa fa-check"></i><b>B.3</b> Matrix-Matrix Operations</a></li>
<li class="chapter" data-level="B.4" data-path="matrix-multiplication.html"><a href="matrix-multiplication.html"><i class="fa fa-check"></i><b>B.4</b> Matrix Multiplication (*)</a></li>
<li class="chapter" data-level="B.5" data-path="matrix-vector-operations.html"><a href="matrix-vector-operations.html"><i class="fa fa-check"></i><b>B.5</b> Matrix-Vector Operations</a></li>
<li class="chapter" data-level="B.6" data-path="further-reading-10.html"><a href="further-reading-10.html"><i class="fa fa-check"></i><b>B.6</b> Further Reading</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="data-frame-wrangling-in-r.html"><a href="data-frame-wrangling-in-r.html"><i class="fa fa-check"></i><b>C</b> Data Frame Wrangling in R</a><ul>
<li class="chapter" data-level="C.1" data-path="to-do.html"><a href="to-do.html"><i class="fa fa-check"></i><b>C.1</b> TO DO</a><ul>
<li class="chapter" data-level="C.1.1" data-path="to-do.html"><a href="to-do.html#to-do-1"><i class="fa fa-check"></i><b>C.1.1</b> TO DO</a></li>
</ul></li>
<li class="chapter" data-level="C.2" data-path="further-reading-11.html"><a href="further-reading-11.html"><i class="fa fa-check"></i><b>C.2</b> Further Reading</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li style='font-size: smaller' ><a href="https://creativecommons.org/licenses/by-nc-nd/4.0/">Licensed under CC BY-NC-ND 4.0</a></li>
<li style='font-size: smaller' ><a href="./">DRAFT v0.1 2020-03-01 16:04 (56335b9)</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Lightweight Machine Learning Classics with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="movielens-dataset" class="section level2">
<h2><span class="header-section-number">9.3</span> MovieLens Dataset (*)</h2>
<div id="dataset" class="section level3">
<h3><span class="header-section-number">9.3.1</span> Dataset</h3>
<hr />
<p>Let us make a few recommendations based on the MovieLens-9/2018-Small
dataset available at
<a href="https://grouplens.org/datasets/movielens/latest/" class="uri">https://grouplens.org/datasets/movielens/latest/</a></p>
<p>The dataset consists of
ca. 100,000 ratings to 9,000 movies by 600 users. Last updated 9/2018.</p>
<p>This is already a pretty large dataset! We might run into problems
with memory usage and run-time.</p>
<p>The following examples are a bit more difficult to follow
(programming-wise), therefore
we mark them with (*).</p>
<p>See also <a href="https://movielens.org/" class="uri">https://movielens.org/</a> and <span class="citation">(Harper &amp; Konstan <a href="references.html#ref-movielens">2015</a>)</span>.</p>
<hr />
<div class="sourceCode" id="cb515"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb515-1" data-line-number="1"><span class="kw">options</span>(<span class="dt">stringsAsFactors=</span><span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb515-2" data-line-number="2">movies &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;datasets/ml-9-2018-small/movies.csv&quot;</span>)</a>
<a class="sourceLine" id="cb515-3" data-line-number="3"><span class="kw">head</span>(movies, <span class="dv">4</span>)</a></code></pre></div>
<pre><code>##   movieId                    title
## 1       1         Toy Story (1995)
## 2       2           Jumanji (1995)
## 3       3  Grumpier Old Men (1995)
## 4       4 Waiting to Exhale (1995)
##                                        genres
## 1 Adventure|Animation|Children|Comedy|Fantasy
## 2                  Adventure|Children|Fantasy
## 3                              Comedy|Romance
## 4                        Comedy|Drama|Romance</code></pre>
<div class="sourceCode" id="cb517"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb517-1" data-line-number="1"><span class="kw">nrow</span>(movies)</a></code></pre></div>
<pre><code>## [1] 9742</code></pre>
<hr />
<div class="sourceCode" id="cb519"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb519-1" data-line-number="1">ratings &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;datasets/ml-9-2018-small/ratings.csv&quot;</span>)</a>
<a class="sourceLine" id="cb519-2" data-line-number="2"><span class="kw">head</span>(ratings, <span class="dv">4</span>)</a></code></pre></div>
<pre><code>##   userId movieId rating timestamp
## 1      1       1      4 964982703
## 2      1       3      4 964981247
## 3      1       6      4 964982224
## 4      1      47      5 964983815</code></pre>
<div class="sourceCode" id="cb521"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb521-1" data-line-number="1"><span class="kw">nrow</span>(ratings)</a></code></pre></div>
<pre><code>## [1] 100836</code></pre>
<div class="sourceCode" id="cb523"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb523-1" data-line-number="1"><span class="kw">table</span>(ratings<span class="op">$</span>rating)</a></code></pre></div>
<pre><code>## 
##   0.5     1   1.5     2   2.5     3   3.5     4   4.5     5 
##  1370  2811  1791  7551  5550 20047 13136 26818  8551 13211</code></pre>
</div>
<div id="data-cleansing" class="section level3">
<h3><span class="header-section-number">9.3.2</span> Data Cleansing</h3>
<hr />
<p><code>movieId</code>s should be re-encoded, as not every film is mentioned/rated in the database.
We will re-map the <code>movieId</code>s to consecutive integers.</p>
<div class="sourceCode" id="cb525"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb525-1" data-line-number="1">movieId2 &lt;-<span class="st"> </span><span class="kw">unique</span>(ratings<span class="op">$</span>movieId) <span class="co"># the list of all rated movieIds</span></a>
<a class="sourceLine" id="cb525-2" data-line-number="2">(m &lt;-<span class="st"> </span><span class="kw">max</span>(ratings<span class="op">$</span>userId)) <span class="co"># max user Id (these could&#39;ve been cleaned up too)]</span></a></code></pre></div>
<pre><code>## [1] 610</code></pre>
<div class="sourceCode" id="cb527"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb527-1" data-line-number="1">(n &lt;-<span class="st"> </span><span class="kw">length</span>(movieId2)) <span class="co"># number of unique movies</span></a></code></pre></div>
<pre><code>## [1] 9724</code></pre>
<div class="sourceCode" id="cb529"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb529-1" data-line-number="1">movies &lt;-<span class="st"> </span>movies[movies<span class="op">$</span>movieId <span class="op">%in%</span><span class="st"> </span>movieId2, ] <span class="co"># remove unrated movies</span></a>
<a class="sourceLine" id="cb529-2" data-line-number="2"><span class="co"># we shall map movieId2[i] to i for each i=1,...,n</span></a>
<a class="sourceLine" id="cb529-3" data-line-number="3">movies<span class="op">$</span>movieId  &lt;-<span class="st"> </span><span class="kw">match</span>(movies<span class="op">$</span>movieId, movieId2)</a>
<a class="sourceLine" id="cb529-4" data-line-number="4">ratings<span class="op">$</span>movieId &lt;-<span class="st"> </span><span class="kw">match</span>(ratings<span class="op">$</span>movieId, movieId2)</a>
<a class="sourceLine" id="cb529-5" data-line-number="5"><span class="co"># order the movies by the new movieId so that</span></a>
<a class="sourceLine" id="cb529-6" data-line-number="6"><span class="co"># the movie with Id=i is at the i-th row.</span></a>
<a class="sourceLine" id="cb529-7" data-line-number="7">movies &lt;-<span class="st"> </span>movies[<span class="kw">order</span>(movies<span class="op">$</span>movieId),]</a>
<a class="sourceLine" id="cb529-8" data-line-number="8"><span class="kw">stopifnot</span>(<span class="kw">all</span>(movies<span class="op">$</span>movieId <span class="op">==</span><span class="st"> </span><span class="dv">1</span><span class="op">:</span>n)) <span class="co"># sanity check</span></a></code></pre></div>
<hr />
<p>We will use a sparse matrix data type (from R package <code>Matrix</code>)
to store ratings data. We don’t want to run out of memory!</p>
<blockquote>
<p>Sparse == many zeros.</p>
</blockquote>
<div class="sourceCode" id="cb530"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb530-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;Matrix&quot;</span>)</a>
<a class="sourceLine" id="cb530-2" data-line-number="2">RML &lt;-<span class="st"> </span><span class="kw">Matrix</span>(<span class="fl">0.0</span>, <span class="dt">sparse=</span><span class="ot">TRUE</span>, <span class="dt">nrow=</span>m, <span class="dt">ncol=</span>n)</a>
<a class="sourceLine" id="cb530-3" data-line-number="3"><span class="co"># This is a vectorised operation;</span></a>
<a class="sourceLine" id="cb530-4" data-line-number="4"><span class="co"># it is faster than a for loop over each row in ratings:</span></a>
<a class="sourceLine" id="cb530-5" data-line-number="5">RML[<span class="kw">cbind</span>(ratings<span class="op">$</span>userId, ratings<span class="op">$</span>movieId)] &lt;-<span class="st"> </span>ratings<span class="op">$</span>rating</a></code></pre></div>
<!--# Not every movie is rated - removing:
RML <- RML[,apply(RML,2,sum)>0]
# Not each user gave a rating - removing:
RML <- RML[apply(RML,1,sum)>0,]-->
<hr />
<div class="sourceCode" id="cb531"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb531-1" data-line-number="1"><span class="co"># Preview:</span></a>
<a class="sourceLine" id="cb531-2" data-line-number="2">RML[<span class="dv">1</span><span class="op">:</span><span class="dv">6</span>, <span class="dv">1</span><span class="op">:</span><span class="dv">18</span>]</a></code></pre></div>
<pre><code>## 6 x 18 sparse Matrix of class &quot;dgCMatrix&quot;
##                                         
## [1,] 4 4 4 5 5 3 5 4 5 5 5 5 3 5 4 5 3 3
## [2,] . . . . . . . . . . . . . . . . . .
## [3,] . . . . . . . . . . . . . . . . . .
## [4,] . . . 2 . . . . . . . . . . 2 5 1 .
## [5,] 4 . . . 4 . . 4 . . . . . . . . 5 2
## [6,] . 5 4 4 1 . . 5 4 . 3 4 . 3 . . 2 5</code></pre>
</div>
<div id="item-item-similarities" class="section level3">
<h3><span class="header-section-number">9.3.3</span> Item-Item Similarities</h3>
<hr />
<p>To recall, the cosine similarity between <span class="math inline">\(\mathbf{a},\mathbf{b}\in\mathbb{R}^m\)</span>
is given by:</p>
<p><span class="math display">\[
S_C(\mathbf{a},\mathbf{b}) = \frac{ \sum_{i=1}^m a_i b_i
    }{
    \sqrt{ \sum_{i=1}^m a_i^2 }
    \sqrt{ \sum_{i=1}^m b_i^2 }
    }
    \]</span></p>
<p>In vector/matrix algebra notation (have you noticed this
section is marked with (*)?), this is:</p>
<p><span class="math display">\[
S_C(\mathbf{a},\mathbf{b}) = \frac{\mathbf{a}^T \mathbf{b}}{
\sqrt{{\mathbf{a}^T \mathbf{a}}} \sqrt{{\mathbf{b}^T \mathbf{b}}}
}
\]</span></p>
<p>If <span class="math inline">\(\mathbf{A}\in\mathbb{R}^{m\times n}\)</span>
we can “almost” compute the all the <span class="math inline">\(n\)</span> cosine similarities at once by applying:</p>
<p><span class="math display">\[
S_C(\mathbf{a},\mathbf{B}) = \frac{\mathbf{A}^T \mathbf{A}}{
\dots
}
\]</span></p>
<hr />
<p>Cosine item-item similarities:</p>
<div class="sourceCode" id="cb533"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb533-1" data-line-number="1">norms &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(<span class="kw">sqrt</span>(<span class="kw">colSums</span>(RML<span class="op">^</span><span class="dv">2</span>)))</a>
<a class="sourceLine" id="cb533-2" data-line-number="2">RMLx &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(<span class="kw">crossprod</span>(RML, RML))</a>
<a class="sourceLine" id="cb533-3" data-line-number="3">SI &lt;-<span class="st"> </span>RMLx<span class="op">/</span><span class="kw">tcrossprod</span>(norms)</a>
<a class="sourceLine" id="cb533-4" data-line-number="4">SI[<span class="kw">is.nan</span>(SI)] &lt;-<span class="st"> </span><span class="dv">0</span> <span class="co"># there were some divisions by zero</span></a></code></pre></div>
<p><code>crossprod(A,B)</code> gives <span class="math inline">\(\mathbf{A}^T \mathbf{B}\)</span></p>
<p><code>tcrossprod(A,B)</code> gives <span class="math inline">\(\mathbf{A} \mathbf{B}^T\)</span></p>
</div>
<div id="example-recommendations" class="section level3">
<h3><span class="header-section-number">9.3.4</span> Example Recommendations</h3>
<hr />
<div class="sourceCode" id="cb534"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb534-1" data-line-number="1">recommend &lt;-<span class="st"> </span><span class="cf">function</span>(i, K, SI, movies) {</a>
<a class="sourceLine" id="cb534-2" data-line-number="2">    <span class="co"># get K most similar movies to the i-th one</span></a>
<a class="sourceLine" id="cb534-3" data-line-number="3">    ms &lt;-<span class="st"> </span><span class="kw">order</span>(SI[i,], <span class="dt">decreasing=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb534-4" data-line-number="4">    tibble<span class="op">::</span><span class="kw">tibble</span>(</a>
<a class="sourceLine" id="cb534-5" data-line-number="5">        <span class="dt">Title=</span>movies<span class="op">$</span>title[ms[<span class="dv">1</span><span class="op">:</span>K]],</a>
<a class="sourceLine" id="cb534-6" data-line-number="6">        <span class="dt">SIC=</span>SI[i,ms[<span class="dv">1</span><span class="op">:</span>K]])</a>
<a class="sourceLine" id="cb534-7" data-line-number="7">}</a></code></pre></div>
<hr />
<div class="sourceCode" id="cb535"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb535-1" data-line-number="1"><span class="kw">recommend</span>(<span class="dv">1215</span>, <span class="dv">10</span>, SI, movies)</a></code></pre></div>
<pre><code>## # A tibble: 10 x 2
##    Title                                              SIC
##    &lt;chr&gt;                                            &lt;dbl&gt;
##  1 Monty Python&#39;s The Meaning of Life (1983)        1    
##  2 Monty Python&#39;s Life of Brian (1979)              0.611
##  3 Monty Python and the Holy Grail (1975)           0.514
##  4 House of Flying Daggers (Shi mian mai fu) (2004) 0.493
##  5 Hitchhiker&#39;s Guide to the Galaxy, The (2005)     0.455
##  6 Bowling for Columbine (2002)                     0.451
##  7 Shaun of the Dead (2004)                         0.446
##  8 O Brother, Where Art Thou? (2000)                0.445
##  9 Ghost World (2001)                               0.444
## 10 Full Metal Jacket (1987)                         0.443</code></pre>
<hr />
<div class="sourceCode" id="cb537"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb537-1" data-line-number="1"><span class="kw">recommend</span>(<span class="dv">1</span>, <span class="dv">10</span>, SI, movies)</a></code></pre></div>
<pre><code>## # A tibble: 10 x 2
##    Title                                               SIC
##    &lt;chr&gt;                                             &lt;dbl&gt;
##  1 Toy Story (1995)                                  1    
##  2 Toy Story 2 (1999)                                0.573
##  3 Jurassic Park (1993)                              0.566
##  4 Independence Day (a.k.a. ID4) (1996)              0.564
##  5 Star Wars: Episode IV - A New Hope (1977)         0.557
##  6 Forrest Gump (1994)                               0.547
##  7 Lion King, The (1994)                             0.541
##  8 Star Wars: Episode VI - Return of the Jedi (1983) 0.541
##  9 Mission: Impossible (1996)                        0.539
## 10 Groundhog Day (1993)                              0.534</code></pre>
<p>…and so on.</p>
</div>
<div id="clustering-2" class="section level3">
<h3><span class="header-section-number">9.3.5</span> Clustering</h3>
<hr />
<p>A cosine similarity matrix can be turned into a dissimilarity matrix:</p>
<div class="sourceCode" id="cb539"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb539-1" data-line-number="1">DI &lt;-<span class="st"> </span><span class="fl">1.0</span><span class="op">-</span>SI</a>
<a class="sourceLine" id="cb539-2" data-line-number="2">DI[DI<span class="op">&lt;</span><span class="dv">0</span>] &lt;-<span class="st"> </span><span class="fl">0.0</span> <span class="co"># account for numeric inaccuracies</span></a>
<a class="sourceLine" id="cb539-3" data-line-number="3">DI &lt;-<span class="st"> </span><span class="kw">as.dist</span>(DI)</a></code></pre></div>
<p>Which enables us to perform, e.g., the cluster analysis of items:</p>
<div class="sourceCode" id="cb540"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb540-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;genie&quot;</span>)</a>
<a class="sourceLine" id="cb540-2" data-line-number="2">h &lt;-<span class="st"> </span><span class="kw">hclust2</span>(DI)</a>
<a class="sourceLine" id="cb540-3" data-line-number="3">c &lt;-<span class="st"> </span><span class="kw">cutree</span>(h, <span class="dt">k=</span><span class="dv">20</span>)</a></code></pre></div>
<hr />
<p>Example movies in the 3rd cluster:</p>
<div class="sourceCode" id="cb541"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb541-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;stringi&quot;</span>)</a>
<a class="sourceLine" id="cb541-2" data-line-number="2"><span class="kw">cat</span>(i, <span class="kw">stri_wrap</span>(<span class="kw">stri_paste</span>(<span class="kw">head</span>(movies<span class="op">$</span>title[c<span class="op">==</span><span class="dv">3</span>], <span class="dv">20</span>),</a>
<a class="sourceLine" id="cb541-3" data-line-number="3">    <span class="dt">collapse=</span><span class="st">&quot;, &quot;</span>)), <span class="dt">sep=</span><span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</a></code></pre></div>
<pre><code>## 5
## Bottle Rocket (1996), Clerks (1994), Star Wars: Episode
## IV - A New Hope (1977), Swingers (1996), Monty Python&#39;s
## Life of Brian (1979), E.T. the Extra-Terrestrial (1982),
## Monty Python and the Holy Grail (1975), Star Wars:
## Episode V - The Empire Strikes Back (1980), Princess
## Bride, The (1987), Raiders of the Lost Ark (Indiana
## Jones and the Raiders of the Lost Ark) (1981), Star Wars:
## Episode VI - Return of the Jedi (1983), Blues Brothers,
## The (1980), Duck Soup (1933), Groundhog Day (1993), Back
## to the Future (1985), Young Frankenstein (1974), Indiana
## Jones and the Last Crusade (1989), Grosse Pointe Blank
## (1997), Austin Powers: International Man of Mystery
## (1997), Men in Black (a.k.a. MIB) (1997)</code></pre>
<hr />
<p>Example movies in the 5th cluster:</p>
<div class="sourceCode" id="cb543"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb543-1" data-line-number="1"><span class="kw">cat</span>(i, <span class="kw">stri_wrap</span>(<span class="kw">stri_paste</span>(<span class="kw">head</span>(movies<span class="op">$</span>title[c<span class="op">==</span><span class="dv">5</span>], <span class="dv">20</span>),</a>
<a class="sourceLine" id="cb543-2" data-line-number="2">    <span class="dt">collapse=</span><span class="st">&quot;, &quot;</span>)), <span class="dt">sep=</span><span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</a></code></pre></div>
<pre><code>## 5
## Blown Away (1994), Flight of the Navigator (1986), Dick
## Tracy (1990), Mighty Aphrodite (1995), Postman, The
## (Postino, Il) (1994), Flirting With Disaster (1996),
## Living in Oblivion (1995), Safe (1995), Eat Drink Man
## Woman (Yin shi nan nu) (1994), Bullets Over Broadway
## (1994), Barcelona (1994), In the Name of the Father
## (1993), Six Degrees of Separation (1993), Maya Lin: A
## Strong Clear Vision (1994), Everyone Says I Love You
## (1996), Rebel Without a Cause (1955), Wings of Desire
## (Himmel über Berlin, Der) (1987), High Noon (1952),
## Afterglow (1997), Bulworth (1998)</code></pre>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="collaborative-filtering.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="outro-8.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": "lmlcr.pdf",
"toc": {
"collapse": "subsection",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
